{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import datetime\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "save_address = 'C:/Users/xi-lucy.chen/Documents/GitLab/data_challenge_alc_total/phase_2_Lucy/feature/'\r\n",
    "wp1 = pd.read_csv(save_address+'wp1.csv')\r\n",
    "wp2 = pd.read_csv(save_address+'wp2.csv')\r\n",
    "wp3 = pd.read_csv(save_address+'wp3.csv')\r\n",
    "wp4 = pd.read_csv(save_address+'wp4.csv')\r\n",
    "wp5 = pd.read_csv(save_address+'wp5.csv')\r\n",
    "wp6 = pd.read_csv(save_address+'wp6.csv')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for wp in [wp1,wp2,wp3,wp4,wp5,wp6]:\r\n",
    "    wp.index = wp['date']\r\n",
    "    wp.drop(columns='date',inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "wp1[0:2]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wp1</th>\n",
       "      <th>train</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>ws</th>\n",
       "      <th>wd</th>\n",
       "      <th>Day sin</th>\n",
       "      <th>Day cos</th>\n",
       "      <th>Year sin</th>\n",
       "      <th>Year cos</th>\n",
       "      <th>...</th>\n",
       "      <th>dff_v_mean</th>\n",
       "      <th>dff_ws_mean</th>\n",
       "      <th>dff_u_1%</th>\n",
       "      <th>dff_v_1%</th>\n",
       "      <th>dff_ws_1%</th>\n",
       "      <th>dff_wd_1%</th>\n",
       "      <th>dff_u_-1%</th>\n",
       "      <th>dff_v_-1%</th>\n",
       "      <th>dff_ws_-1%</th>\n",
       "      <th>dff_wd_-1%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-07-01 00:00:00</th>\n",
       "      <td>0.051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.14</td>\n",
       "      <td>-3.62</td>\n",
       "      <td>4.79</td>\n",
       "      <td>139.09</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.015690</td>\n",
       "      <td>-0.999877</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.158256</td>\n",
       "      <td>-0.795149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-01 01:00:00</th>\n",
       "      <td>0.051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.14</td>\n",
       "      <td>-3.62</td>\n",
       "      <td>4.79</td>\n",
       "      <td>139.09</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.014973</td>\n",
       "      <td>-0.999888</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.158250</td>\n",
       "      <td>-0.795237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.008412</td>\n",
       "      <td>0.057325</td>\n",
       "      <td>0.016575</td>\n",
       "      <td>0.033403</td>\n",
       "      <td>-0.008412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       wp1  train     u     v    ws      wd   Day sin  \\\n",
       "date                                                                    \n",
       "2009-07-01 00:00:00  0.051    1.0  3.14 -3.62  4.79  139.09  0.866025   \n",
       "2009-07-01 01:00:00  0.051    1.0  3.14 -3.62  4.79  139.09  0.965926   \n",
       "\n",
       "                      Day cos  Year sin  Year cos  ...  dff_v_mean  \\\n",
       "date                                               ...               \n",
       "2009-07-01 00:00:00  0.500000  0.015690 -0.999877  ...   -3.158256   \n",
       "2009-07-01 01:00:00  0.258819  0.014973 -0.999888  ...   -3.158250   \n",
       "\n",
       "                     dff_ws_mean  dff_u_1%  dff_v_1%  dff_ws_1%  dff_wd_1%  \\\n",
       "date                                                                         \n",
       "2009-07-01 00:00:00    -0.795149       NaN       NaN        NaN   0.000000   \n",
       "2009-07-01 01:00:00    -0.795237       0.0      -0.0        0.0  -0.008412   \n",
       "\n",
       "                     dff_u_-1%  dff_v_-1%  dff_ws_-1%  dff_wd_-1%  \n",
       "date                                                               \n",
       "2009-07-01 00:00:00   0.000000  -0.000000    0.000000    0.000000  \n",
       "2009-07-01 01:00:00   0.057325   0.016575    0.033403   -0.008412  \n",
       "\n",
       "[2 rows x 43 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_X(df):\r\n",
    "    return df.iloc[:, 2:]\r\n",
    "\r\n",
    "def get_y(df, name='wp1'):\r\n",
    "    return df[name]\r\n",
    "\r\n",
    "def get_X_test(df):\r\n",
    "    return df.iloc[:, 1:]\r\n",
    "\r\n",
    "\r\n",
    "def data_test_split(df, model_address, start_date=\"2009-07-01 00:00:00\", end_date=\"2010-12-31 23:00:00\", name='wp1'):\r\n",
    "    '''\r\n",
    "    resplit data & test from full data\r\n",
    "    '''\r\n",
    "    train = df[df['train'] == 1].sort_values(by='date')\r\n",
    "    test = df[df['train'] != 1].sort_values(by='date')\r\n",
    "    train = train.drop(columns=['train'])\r\n",
    "    test = test.drop(columns=['train', name])\r\n",
    "    train = train.loc[start_date:end_date]\r\n",
    "    train.to_csv(model_address+'training_data_{}.csv'.format(name))\r\n",
    "    X_train = get_X(train)\r\n",
    "    y_train = get_y(train, name)\r\n",
    "    X_forecast = get_X_test(test)\r\n",
    "    return X_train, y_train, X_forecast ,test # train, test,\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Split"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "\r\n",
    "def split_data(X, y):\r\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\r\n",
    "        X, y, test_size=0.2, random_state=177)\r\n",
    "    return X_train, X_test, y_train, y_test\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# XGBOOST"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import model1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "tune_parameter = False\r\n",
    "grid_search = False\r\n",
    "params = {'colsample_bytree': 0.6,\r\n",
    "          'max_depth': 13,\r\n",
    "          'min_child_weight': 9,\r\n",
    "          'eval_metric': 'mae',\r\n",
    "          'subsample': 0.6,\r\n",
    "          'colsample': 1.0,\r\n",
    "          'eta': 0.05}\r\n",
    "\r\n",
    "num_boost_round = 1000"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# FORECAST"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def prediction(X_forecast, test, model, name):\r\n",
    "    X_forecast = xgb.DMatrix(data=X_forecast)\r\n",
    "    df_predictions = pd.DataFrame({\r\n",
    "        'date': test.index,\r\n",
    "        name: model.predict(X_forecast),\r\n",
    "    })\r\n",
    "    save_address = 'C:/Users/xi-lucy.chen/Documents/GitLab/data_challenge_alc_total/phase 2 model/Lucy/result/'\r\n",
    "    df_predictions.to_csv(save_address+\"pred_{}.csv\".format(name))\r\n",
    "    return df_predictions\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RUNNNNNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#from pandas.io.json import json_normalize\r\n",
    "from datetime import date\r\n",
    "import json\r\n",
    "import gc\r\n",
    "#param_list = pd.DataFrame()\r\n",
    "prediction = pd.DataFrame()\r\n",
    "start_date = \"2009-07-01 00:00:00\"\r\n",
    "end_date = \"2010-12-31 23:00:00\"\r\n",
    "\r\n",
    "save_address = 'C:/Users/xi-lucy.chen/Documents/GitLab/data_challenge_alc_total/phase_2_Lucy/result/'\r\n",
    "model_address = 'C:/Users/xi-lucy.chen/Documents/GitLab/data_challenge_alc_total/phase_2_Lucy/model/'\r\n",
    "months_predict = ['201101', '201102', '201103','201104','201105','201106','201107','201108','201109','201110','201111','201112','201201','201202','201203','201204','201205','201206']\r\n",
    "train_end_date = [\"2010-12-31 23:00:00\",\r\n",
    "                \"2011-01-31 23:00:00\",\r\n",
    "                \"2011-02-28 23:00:00\",\r\n",
    "                \"2011-03-31 23:00:00\",\r\n",
    "                \"2011-04-30 23:00:00\",\r\n",
    "                \"2011-05-30 23:00:00\",\r\n",
    "                \"2011-06-30 23:00:00\",\r\n",
    "                \"2011-07-31 23:00:00\",\r\n",
    "                \"2011-08-31 23:00:00\",\r\n",
    "                \"2011-09-30 23:00:00\",\r\n",
    "                \"2011-10-31 23:00:00\",  \r\n",
    "                \"2011-11-30 23:00:00\",\r\n",
    "                \"2011-12-31 23:00:00\",\r\n",
    "                \"2012-01-31 23:00:00\",\r\n",
    "                \"2012-02-29 23:00:00\",\r\n",
    "                \"2012-03-31 23:00:00\",\r\n",
    "                \"2012-04-30 23:00:00\",\r\n",
    "                \"2012-05-31 23:00:00\"]\r\n",
    "\r\n",
    "for year, end_date in zip(months_predict, train_end_date):\r\n",
    "    # for name,df in zip([\"wp1\", \"wp2\", \"wp3\", \"wp4\", \"wp5\", \"wp6\"],[wp1,wp2,wp3,wp4,wp5,wp6]):\r\n",
    "    #     print('------ name is :', name, \"------\")\r\n",
    "    #     #split my merged dataset\r\n",
    "    #     X, y, X_forecast,test = data_test_split(df, model_address=model_address, start_date=start_date, end_date=end_date, name=name)\r\n",
    "    #     #split to train model\r\n",
    "    #     '''we do the modification here'''\r\n",
    "    for name_1, df_1 in zip([\"wp1\", \"wp2\", \"wp3\", \"wp4\", \"wp5\", \"wp6\"], [wp1, wp2, wp3, wp4, wp5, wp6]):\r\n",
    "            print('I am merging ..',name_1)\r\n",
    "            X_temp, y_temp, X_forecast_temp,test_temp = data_test_split(\r\n",
    "                df_1, model_address=model_address, start_date=start_date, end_date=end_date, name=name_1)\r\n",
    "            test_temp['wp'] = name_1\r\n",
    "            if name_1 == 'wp1':\r\n",
    "                my_X = X_temp\r\n",
    "                my_y = y_temp\r\n",
    "                my_X_forecast = X_forecast_temp\r\n",
    "                my_test =test_temp\r\n",
    "                print('my X length is..', len(my_X))\r\n",
    "                print('my y length is..', len(my_y))\r\n",
    "            else:\r\n",
    "                my_X = my_X.append(X_temp)\r\n",
    "                my_y = my_y.append(y_temp)\r\n",
    "                my_X_forecast = my_X_forecast.append(X_forecast_temp)\r\n",
    "                my_test = my_test.append(test_temp)\r\n",
    "                print('my X length is..', len(my_X))\r\n",
    "                print('my y length is..', len(my_y))\r\n",
    "                print('my_X_forecast length is..', len(my_X_forecast))\r\n",
    "                print('my_test length is..', len(my_test))\r\n",
    "                del X_temp, y_temp, X_forecast_temp, test_temp\r\n",
    "                gc.collect()\r\n",
    "\r\n",
    "    X = my_X\r\n",
    "    y = my_y\r\n",
    "    X_forecast = my_X_forecast\r\n",
    "    test=my_test\r\n",
    "\r\n",
    "    ''''''\r\n",
    "    X_train, X_test, y_train, y_test = split_data(X,y)\r\n",
    "    model,param = model1.run_xgb(X_train, X_test, y_train, y_test, params, num_boost_round=num_boost_round,\r\n",
    "                            tune_parameter=True, grid_search=False, graph=False)\r\n",
    "    '''\r\n",
    "    Forecast\r\n",
    "    '''\r\n",
    "    X_forecast = xgb.DMatrix(data=X_forecast)\r\n",
    "    df_predictions = pd.DataFrame({\r\n",
    "            'date': test.index,\r\n",
    "            'wp':test['wp'],\r\n",
    "            \"forecast\": model.predict(X_forecast),\r\n",
    "        })\r\n",
    "    model.save_model(model_address+\"model_merged_train.json\")\r\n",
    "        #df_predictions.to_csv(save_address+\"pred_{}.csv\".format(name))\r\n",
    "        #print(param)\r\n",
    "        #print(type(param)) #This is string type\r\n",
    "        #param = json.loads(param)\r\n",
    "    with open(model_address+\"param_merged_train_{}.json\".format(year), 'w') as f:\r\n",
    "            json.dump(param, f)\r\n",
    "        #param_list = param_list.append(param)\r\n",
    "    # if name =='wp1':\r\n",
    "    #         prediction = df_predictions\r\n",
    "    #     else:\r\n",
    "    #         prediction = prediction.merge(df_predictions,on=['date'])\r\n",
    "    prediction= pd.pivot_table(df_predictions, index=df_predictions.index,\r\n",
    "                   columns='wp', values='forecast', aggfunc=min).reset_index()\r\n",
    "\r\n",
    "    prediction.rename(columns={'date': 'date1'}, inplace=True)\r\n",
    "    data_path = 'C:/Users/xi-lucy.chen/Documents/GitLab/data_challenge_alc_total/data/'\r\n",
    "    test = pd.read_csv(f'{data_path}test.csv')\r\n",
    "    prediction = pd.concat([test, prediction], axis=1)\r\n",
    "    prediction.drop(columns='date1', inplace=True)\r\n",
    "\r\n",
    "    save_address = 'C:/Users/xi-lucy.chen/Documents/GitLab/data_challenge_alc_total/phase_2_Lucy/result/before_submission/'\r\n",
    "    prediction.to_csv(\r\n",
    "    save_address+'predictions_end_date_{}.csv'.format(year), index=False, sep=';')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "I am merging .. wp1\n",
      "my X length is.. 13176\n",
      "my y length is.. 13176\n",
      "I am merging .. wp2\n",
      "my X length is.. 26352\n",
      "my y length is.. 26352\n",
      "my_X_forecast length is.. 14880\n",
      "my_test length is.. 14880\n",
      "I am merging .. wp3\n",
      "my X length is.. 39528\n",
      "my y length is.. 39528\n",
      "my_X_forecast length is.. 22320\n",
      "my_test length is.. 22320\n",
      "I am merging .. wp4\n",
      "my X length is.. 52704\n",
      "my y length is.. 52704\n",
      "my_X_forecast length is.. 29760\n",
      "my_test length is.. 29760\n",
      "I am merging .. wp5\n",
      "my X length is.. 65880\n",
      "my y length is.. 65880\n",
      "my_X_forecast length is.. 37200\n",
      "my_test length is.. 37200\n",
      "I am merging .. wp6\n",
      "my X length is.. 79056\n",
      "my y length is.. 79056\n",
      "my_X_forecast length is.. 44640\n",
      "my_test length is.. 44640\n",
      "Baseline MAE is 0.23\n",
      "[21:03:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tTest-mae:0.31454\n",
      "Will train until Test-mae hasn't improved in 1000 rounds.\n",
      "[1]\tTest-mae:0.30167\n",
      "[2]\tTest-mae:0.28963\n",
      "[3]\tTest-mae:0.27808\n",
      "[4]\tTest-mae:0.26707\n",
      "[5]\tTest-mae:0.25679\n",
      "[6]\tTest-mae:0.24698\n",
      "[7]\tTest-mae:0.23775\n",
      "[8]\tTest-mae:0.22916\n",
      "[9]\tTest-mae:0.22095\n",
      "[10]\tTest-mae:0.21328\n",
      "[11]\tTest-mae:0.20579\n",
      "[12]\tTest-mae:0.19900\n",
      "[13]\tTest-mae:0.19217\n",
      "[14]\tTest-mae:0.18596\n",
      "[15]\tTest-mae:0.17998\n",
      "[16]\tTest-mae:0.17441\n",
      "[17]\tTest-mae:0.16917\n",
      "[18]\tTest-mae:0.16424\n",
      "[19]\tTest-mae:0.15941\n",
      "[20]\tTest-mae:0.15494\n",
      "[21]\tTest-mae:0.15079\n",
      "[22]\tTest-mae:0.14677\n",
      "[23]\tTest-mae:0.14296\n",
      "[24]\tTest-mae:0.13961\n",
      "[25]\tTest-mae:0.13627\n",
      "[26]\tTest-mae:0.13308\n",
      "[27]\tTest-mae:0.13029\n",
      "[28]\tTest-mae:0.12744\n",
      "[29]\tTest-mae:0.12480\n",
      "[30]\tTest-mae:0.12234\n",
      "[31]\tTest-mae:0.11999\n",
      "[32]\tTest-mae:0.11786\n",
      "[33]\tTest-mae:0.11570\n",
      "[34]\tTest-mae:0.11375\n",
      "[35]\tTest-mae:0.11184\n",
      "[36]\tTest-mae:0.11010\n",
      "[37]\tTest-mae:0.10838\n",
      "[38]\tTest-mae:0.10681\n",
      "[39]\tTest-mae:0.10533\n",
      "[40]\tTest-mae:0.10405\n",
      "[41]\tTest-mae:0.10268\n",
      "[42]\tTest-mae:0.10142\n",
      "[43]\tTest-mae:0.10032\n",
      "[44]\tTest-mae:0.09938\n",
      "[45]\tTest-mae:0.09838\n",
      "[46]\tTest-mae:0.09733\n",
      "[47]\tTest-mae:0.09638\n",
      "[48]\tTest-mae:0.09559\n",
      "[49]\tTest-mae:0.09474\n",
      "[50]\tTest-mae:0.09402\n",
      "[51]\tTest-mae:0.09323\n",
      "[52]\tTest-mae:0.09246\n",
      "[53]\tTest-mae:0.09176\n",
      "[54]\tTest-mae:0.09118\n",
      "[55]\tTest-mae:0.09052\n",
      "[56]\tTest-mae:0.08995\n",
      "[57]\tTest-mae:0.08938\n",
      "[58]\tTest-mae:0.08879\n",
      "[59]\tTest-mae:0.08828\n",
      "[60]\tTest-mae:0.08784\n",
      "[61]\tTest-mae:0.08740\n",
      "[62]\tTest-mae:0.08696\n",
      "[63]\tTest-mae:0.08657\n",
      "[64]\tTest-mae:0.08612\n",
      "[65]\tTest-mae:0.08576\n",
      "[66]\tTest-mae:0.08540\n",
      "[67]\tTest-mae:0.08507\n",
      "[68]\tTest-mae:0.08472\n",
      "[69]\tTest-mae:0.08443\n",
      "[70]\tTest-mae:0.08408\n",
      "[71]\tTest-mae:0.08383\n",
      "[72]\tTest-mae:0.08358\n",
      "[73]\tTest-mae:0.08336\n",
      "[74]\tTest-mae:0.08314\n",
      "[75]\tTest-mae:0.08291\n",
      "[76]\tTest-mae:0.08267\n",
      "[77]\tTest-mae:0.08242\n",
      "[78]\tTest-mae:0.08220\n",
      "[79]\tTest-mae:0.08198\n",
      "[80]\tTest-mae:0.08177\n",
      "[81]\tTest-mae:0.08156\n",
      "[82]\tTest-mae:0.08137\n",
      "[83]\tTest-mae:0.08119\n",
      "[84]\tTest-mae:0.08097\n",
      "[85]\tTest-mae:0.08078\n",
      "[86]\tTest-mae:0.08068\n",
      "[87]\tTest-mae:0.08053\n",
      "[88]\tTest-mae:0.08037\n",
      "[89]\tTest-mae:0.08022\n",
      "[90]\tTest-mae:0.08003\n",
      "[91]\tTest-mae:0.07987\n",
      "[92]\tTest-mae:0.07970\n",
      "[93]\tTest-mae:0.07950\n",
      "[94]\tTest-mae:0.07938\n",
      "[95]\tTest-mae:0.07921\n",
      "[96]\tTest-mae:0.07912\n",
      "[97]\tTest-mae:0.07903\n",
      "[98]\tTest-mae:0.07898\n",
      "[99]\tTest-mae:0.07884\n",
      "[100]\tTest-mae:0.07874\n",
      "[101]\tTest-mae:0.07866\n",
      "[102]\tTest-mae:0.07857\n",
      "[103]\tTest-mae:0.07849\n",
      "[104]\tTest-mae:0.07840\n",
      "[105]\tTest-mae:0.07823\n",
      "[106]\tTest-mae:0.07815\n",
      "[107]\tTest-mae:0.07805\n",
      "[108]\tTest-mae:0.07802\n",
      "[109]\tTest-mae:0.07797\n",
      "[110]\tTest-mae:0.07790\n",
      "[111]\tTest-mae:0.07776\n",
      "[112]\tTest-mae:0.07766\n",
      "[113]\tTest-mae:0.07761\n",
      "[114]\tTest-mae:0.07755\n",
      "[115]\tTest-mae:0.07750\n",
      "[116]\tTest-mae:0.07746\n",
      "[117]\tTest-mae:0.07735\n",
      "[118]\tTest-mae:0.07722\n",
      "[119]\tTest-mae:0.07704\n",
      "[120]\tTest-mae:0.07694\n",
      "[121]\tTest-mae:0.07689\n",
      "[122]\tTest-mae:0.07687\n",
      "[123]\tTest-mae:0.07679\n",
      "[124]\tTest-mae:0.07676\n",
      "[125]\tTest-mae:0.07668\n",
      "[126]\tTest-mae:0.07662\n",
      "[127]\tTest-mae:0.07655\n",
      "[128]\tTest-mae:0.07651\n",
      "[129]\tTest-mae:0.07645\n",
      "[130]\tTest-mae:0.07642\n",
      "[131]\tTest-mae:0.07641\n",
      "[132]\tTest-mae:0.07634\n",
      "[133]\tTest-mae:0.07628\n",
      "[134]\tTest-mae:0.07624\n",
      "[135]\tTest-mae:0.07620\n",
      "[136]\tTest-mae:0.07612\n",
      "[137]\tTest-mae:0.07601\n",
      "[138]\tTest-mae:0.07599\n",
      "[139]\tTest-mae:0.07592\n",
      "[140]\tTest-mae:0.07587\n",
      "[141]\tTest-mae:0.07582\n",
      "[142]\tTest-mae:0.07570\n",
      "[143]\tTest-mae:0.07564\n",
      "[144]\tTest-mae:0.07558\n",
      "[145]\tTest-mae:0.07552\n",
      "[146]\tTest-mae:0.07550\n",
      "[147]\tTest-mae:0.07544\n",
      "[148]\tTest-mae:0.07539\n",
      "[149]\tTest-mae:0.07536\n",
      "[150]\tTest-mae:0.07534\n",
      "[151]\tTest-mae:0.07531\n",
      "[152]\tTest-mae:0.07518\n",
      "[153]\tTest-mae:0.07515\n",
      "[154]\tTest-mae:0.07514\n",
      "[155]\tTest-mae:0.07506\n",
      "[156]\tTest-mae:0.07501\n",
      "[157]\tTest-mae:0.07501\n",
      "[158]\tTest-mae:0.07496\n",
      "[159]\tTest-mae:0.07490\n",
      "[160]\tTest-mae:0.07489\n",
      "[161]\tTest-mae:0.07486\n",
      "[162]\tTest-mae:0.07479\n",
      "[163]\tTest-mae:0.07469\n",
      "[164]\tTest-mae:0.07463\n",
      "[165]\tTest-mae:0.07460\n",
      "[166]\tTest-mae:0.07456\n",
      "[167]\tTest-mae:0.07453\n",
      "[168]\tTest-mae:0.07448\n",
      "[169]\tTest-mae:0.07444\n",
      "[170]\tTest-mae:0.07444\n",
      "[171]\tTest-mae:0.07438\n",
      "[172]\tTest-mae:0.07434\n",
      "[173]\tTest-mae:0.07432\n",
      "[174]\tTest-mae:0.07431\n",
      "[175]\tTest-mae:0.07428\n",
      "[176]\tTest-mae:0.07424\n",
      "[177]\tTest-mae:0.07423\n",
      "[178]\tTest-mae:0.07420\n",
      "[179]\tTest-mae:0.07416\n",
      "[180]\tTest-mae:0.07417\n",
      "[181]\tTest-mae:0.07410\n",
      "[182]\tTest-mae:0.07408\n",
      "[183]\tTest-mae:0.07407\n",
      "[184]\tTest-mae:0.07404\n",
      "[185]\tTest-mae:0.07404\n",
      "[186]\tTest-mae:0.07403\n",
      "[187]\tTest-mae:0.07395\n",
      "[188]\tTest-mae:0.07391\n",
      "[189]\tTest-mae:0.07390\n",
      "[190]\tTest-mae:0.07389\n",
      "[191]\tTest-mae:0.07385\n",
      "[192]\tTest-mae:0.07383\n",
      "[193]\tTest-mae:0.07382\n",
      "[194]\tTest-mae:0.07378\n",
      "[195]\tTest-mae:0.07375\n",
      "[196]\tTest-mae:0.07369\n",
      "[197]\tTest-mae:0.07366\n",
      "[198]\tTest-mae:0.07363\n",
      "[199]\tTest-mae:0.07361\n",
      "[200]\tTest-mae:0.07356\n",
      "[201]\tTest-mae:0.07355\n",
      "[202]\tTest-mae:0.07351\n",
      "[203]\tTest-mae:0.07347\n",
      "[204]\tTest-mae:0.07346\n",
      "[205]\tTest-mae:0.07345\n",
      "[206]\tTest-mae:0.07342\n",
      "[207]\tTest-mae:0.07341\n",
      "[208]\tTest-mae:0.07336\n",
      "[209]\tTest-mae:0.07335\n",
      "[210]\tTest-mae:0.07334\n",
      "[211]\tTest-mae:0.07333\n",
      "[212]\tTest-mae:0.07329\n",
      "[213]\tTest-mae:0.07327\n",
      "[214]\tTest-mae:0.07323\n",
      "[215]\tTest-mae:0.07319\n",
      "[216]\tTest-mae:0.07317\n",
      "[217]\tTest-mae:0.07315\n",
      "[218]\tTest-mae:0.07313\n",
      "[219]\tTest-mae:0.07310\n",
      "[220]\tTest-mae:0.07305\n",
      "[221]\tTest-mae:0.07302\n",
      "[222]\tTest-mae:0.07301\n",
      "[223]\tTest-mae:0.07296\n",
      "[224]\tTest-mae:0.07292\n",
      "[225]\tTest-mae:0.07292\n",
      "[226]\tTest-mae:0.07290\n",
      "[227]\tTest-mae:0.07290\n",
      "[228]\tTest-mae:0.07288\n",
      "[229]\tTest-mae:0.07287\n",
      "[230]\tTest-mae:0.07284\n",
      "[231]\tTest-mae:0.07283\n",
      "[232]\tTest-mae:0.07280\n",
      "[233]\tTest-mae:0.07278\n",
      "[234]\tTest-mae:0.07275\n",
      "[235]\tTest-mae:0.07275\n",
      "[236]\tTest-mae:0.07270\n",
      "[237]\tTest-mae:0.07269\n",
      "[238]\tTest-mae:0.07264\n",
      "[239]\tTest-mae:0.07261\n",
      "[240]\tTest-mae:0.07259\n",
      "[241]\tTest-mae:0.07258\n",
      "[242]\tTest-mae:0.07253\n",
      "[243]\tTest-mae:0.07248\n",
      "[244]\tTest-mae:0.07247\n",
      "[245]\tTest-mae:0.07243\n",
      "[246]\tTest-mae:0.07240\n",
      "[247]\tTest-mae:0.07239\n",
      "[248]\tTest-mae:0.07237\n",
      "[249]\tTest-mae:0.07236\n",
      "[250]\tTest-mae:0.07235\n",
      "[251]\tTest-mae:0.07235\n",
      "[252]\tTest-mae:0.07234\n",
      "[253]\tTest-mae:0.07234\n",
      "[254]\tTest-mae:0.07233\n",
      "[255]\tTest-mae:0.07232\n",
      "[256]\tTest-mae:0.07229\n",
      "[257]\tTest-mae:0.07228\n",
      "[258]\tTest-mae:0.07226\n",
      "[259]\tTest-mae:0.07225\n",
      "[260]\tTest-mae:0.07222\n",
      "[261]\tTest-mae:0.07218\n",
      "[262]\tTest-mae:0.07215\n",
      "[263]\tTest-mae:0.07212\n",
      "[264]\tTest-mae:0.07211\n",
      "[265]\tTest-mae:0.07208\n",
      "[266]\tTest-mae:0.07206\n",
      "[267]\tTest-mae:0.07206\n",
      "[268]\tTest-mae:0.07203\n",
      "[269]\tTest-mae:0.07202\n",
      "[270]\tTest-mae:0.07199\n",
      "[271]\tTest-mae:0.07199\n",
      "[272]\tTest-mae:0.07199\n",
      "[273]\tTest-mae:0.07196\n",
      "[274]\tTest-mae:0.07195\n",
      "[275]\tTest-mae:0.07194\n",
      "[276]\tTest-mae:0.07192\n",
      "[277]\tTest-mae:0.07189\n",
      "[278]\tTest-mae:0.07188\n",
      "[279]\tTest-mae:0.07188\n",
      "[280]\tTest-mae:0.07187\n",
      "[281]\tTest-mae:0.07186\n",
      "[282]\tTest-mae:0.07183\n",
      "[283]\tTest-mae:0.07180\n",
      "[284]\tTest-mae:0.07178\n",
      "[285]\tTest-mae:0.07175\n",
      "[286]\tTest-mae:0.07175\n",
      "[287]\tTest-mae:0.07175\n",
      "[288]\tTest-mae:0.07173\n",
      "[289]\tTest-mae:0.07173\n",
      "[290]\tTest-mae:0.07171\n",
      "[291]\tTest-mae:0.07168\n",
      "[292]\tTest-mae:0.07166\n",
      "[293]\tTest-mae:0.07164\n",
      "[294]\tTest-mae:0.07164\n",
      "[295]\tTest-mae:0.07163\n",
      "[296]\tTest-mae:0.07161\n",
      "[297]\tTest-mae:0.07161\n",
      "[298]\tTest-mae:0.07159\n",
      "[299]\tTest-mae:0.07157\n",
      "[300]\tTest-mae:0.07155\n",
      "[301]\tTest-mae:0.07155\n",
      "[302]\tTest-mae:0.07151\n",
      "[303]\tTest-mae:0.07150\n",
      "[304]\tTest-mae:0.07150\n",
      "[305]\tTest-mae:0.07146\n",
      "[306]\tTest-mae:0.07146\n",
      "[307]\tTest-mae:0.07144\n",
      "[308]\tTest-mae:0.07144\n",
      "[309]\tTest-mae:0.07143\n",
      "[310]\tTest-mae:0.07140\n",
      "[311]\tTest-mae:0.07139\n",
      "[312]\tTest-mae:0.07136\n",
      "[313]\tTest-mae:0.07136\n",
      "[314]\tTest-mae:0.07135\n",
      "[315]\tTest-mae:0.07134\n",
      "[316]\tTest-mae:0.07131\n",
      "[317]\tTest-mae:0.07130\n",
      "[318]\tTest-mae:0.07129\n",
      "[319]\tTest-mae:0.07128\n",
      "[320]\tTest-mae:0.07128\n",
      "[321]\tTest-mae:0.07128\n",
      "[322]\tTest-mae:0.07126\n",
      "[323]\tTest-mae:0.07125\n",
      "[324]\tTest-mae:0.07125\n",
      "[325]\tTest-mae:0.07124\n",
      "[326]\tTest-mae:0.07124\n",
      "[327]\tTest-mae:0.07123\n",
      "[328]\tTest-mae:0.07119\n",
      "[329]\tTest-mae:0.07117\n",
      "[330]\tTest-mae:0.07115\n",
      "[331]\tTest-mae:0.07115\n",
      "[332]\tTest-mae:0.07114\n",
      "[333]\tTest-mae:0.07114\n",
      "[334]\tTest-mae:0.07111\n",
      "[335]\tTest-mae:0.07109\n",
      "[336]\tTest-mae:0.07107\n",
      "[337]\tTest-mae:0.07104\n",
      "[338]\tTest-mae:0.07099\n",
      "[339]\tTest-mae:0.07099\n",
      "[340]\tTest-mae:0.07097\n",
      "[341]\tTest-mae:0.07096\n",
      "[342]\tTest-mae:0.07095\n",
      "[343]\tTest-mae:0.07094\n",
      "[344]\tTest-mae:0.07092\n",
      "[345]\tTest-mae:0.07090\n",
      "[346]\tTest-mae:0.07089\n",
      "[347]\tTest-mae:0.07088\n",
      "[348]\tTest-mae:0.07088\n",
      "[349]\tTest-mae:0.07087\n",
      "[350]\tTest-mae:0.07085\n",
      "[351]\tTest-mae:0.07085\n",
      "[352]\tTest-mae:0.07082\n",
      "[353]\tTest-mae:0.07081\n",
      "[354]\tTest-mae:0.07080\n",
      "[355]\tTest-mae:0.07078\n",
      "[356]\tTest-mae:0.07078\n",
      "[357]\tTest-mae:0.07077\n",
      "[358]\tTest-mae:0.07076\n",
      "[359]\tTest-mae:0.07073\n",
      "[360]\tTest-mae:0.07073\n",
      "[361]\tTest-mae:0.07072\n",
      "[362]\tTest-mae:0.07072\n",
      "[363]\tTest-mae:0.07071\n",
      "[364]\tTest-mae:0.07070\n",
      "[365]\tTest-mae:0.07069\n",
      "[366]\tTest-mae:0.07068\n",
      "[367]\tTest-mae:0.07067\n",
      "[368]\tTest-mae:0.07068\n",
      "[369]\tTest-mae:0.07067\n",
      "[370]\tTest-mae:0.07066\n",
      "[371]\tTest-mae:0.07065\n",
      "[372]\tTest-mae:0.07063\n",
      "[373]\tTest-mae:0.07063\n",
      "[374]\tTest-mae:0.07062\n",
      "[375]\tTest-mae:0.07061\n",
      "[376]\tTest-mae:0.07061\n",
      "[377]\tTest-mae:0.07059\n",
      "[378]\tTest-mae:0.07058\n",
      "[379]\tTest-mae:0.07057\n",
      "[380]\tTest-mae:0.07055\n",
      "[381]\tTest-mae:0.07054\n",
      "[382]\tTest-mae:0.07053\n",
      "[383]\tTest-mae:0.07052\n",
      "[384]\tTest-mae:0.07051\n",
      "[385]\tTest-mae:0.07048\n",
      "[386]\tTest-mae:0.07046\n",
      "[387]\tTest-mae:0.07045\n",
      "[388]\tTest-mae:0.07044\n",
      "[389]\tTest-mae:0.07041\n",
      "[390]\tTest-mae:0.07040\n",
      "[391]\tTest-mae:0.07040\n",
      "[392]\tTest-mae:0.07041\n",
      "[393]\tTest-mae:0.07040\n",
      "[394]\tTest-mae:0.07038\n",
      "[395]\tTest-mae:0.07038\n",
      "[396]\tTest-mae:0.07037\n",
      "[397]\tTest-mae:0.07036\n",
      "[398]\tTest-mae:0.07034\n",
      "[399]\tTest-mae:0.07033\n",
      "[400]\tTest-mae:0.07032\n",
      "[401]\tTest-mae:0.07031\n",
      "[402]\tTest-mae:0.07030\n",
      "[403]\tTest-mae:0.07029\n",
      "[404]\tTest-mae:0.07028\n",
      "[405]\tTest-mae:0.07028\n",
      "[406]\tTest-mae:0.07027\n",
      "[407]\tTest-mae:0.07026\n",
      "[408]\tTest-mae:0.07026\n",
      "[409]\tTest-mae:0.07026\n",
      "[410]\tTest-mae:0.07025\n",
      "[411]\tTest-mae:0.07022\n",
      "[412]\tTest-mae:0.07022\n",
      "[413]\tTest-mae:0.07021\n",
      "[414]\tTest-mae:0.07018\n",
      "[415]\tTest-mae:0.07017\n",
      "[416]\tTest-mae:0.07016\n",
      "[417]\tTest-mae:0.07015\n",
      "[418]\tTest-mae:0.07015\n",
      "[419]\tTest-mae:0.07014\n",
      "[420]\tTest-mae:0.07014\n",
      "[421]\tTest-mae:0.07013\n",
      "[422]\tTest-mae:0.07011\n",
      "[423]\tTest-mae:0.07011\n",
      "[424]\tTest-mae:0.07010\n",
      "[425]\tTest-mae:0.07010\n",
      "[426]\tTest-mae:0.07009\n",
      "[427]\tTest-mae:0.07008\n",
      "[428]\tTest-mae:0.07007\n",
      "[429]\tTest-mae:0.07006\n",
      "[430]\tTest-mae:0.07005\n",
      "[431]\tTest-mae:0.07004\n",
      "[432]\tTest-mae:0.07004\n",
      "[433]\tTest-mae:0.07004\n",
      "[434]\tTest-mae:0.07003\n",
      "[435]\tTest-mae:0.07002\n",
      "[436]\tTest-mae:0.07002\n",
      "[437]\tTest-mae:0.07001\n",
      "[438]\tTest-mae:0.07000\n",
      "[439]\tTest-mae:0.07000\n",
      "[440]\tTest-mae:0.06999\n",
      "[441]\tTest-mae:0.06998\n",
      "[442]\tTest-mae:0.06998\n",
      "[443]\tTest-mae:0.06998\n",
      "[444]\tTest-mae:0.06997\n",
      "[445]\tTest-mae:0.06997\n",
      "[446]\tTest-mae:0.06997\n",
      "[447]\tTest-mae:0.06996\n",
      "[448]\tTest-mae:0.06996\n",
      "[449]\tTest-mae:0.06996\n",
      "[450]\tTest-mae:0.06995\n",
      "[451]\tTest-mae:0.06994\n",
      "[452]\tTest-mae:0.06994\n",
      "[453]\tTest-mae:0.06993\n",
      "[454]\tTest-mae:0.06992\n",
      "[455]\tTest-mae:0.06990\n",
      "[456]\tTest-mae:0.06990\n",
      "[457]\tTest-mae:0.06989\n",
      "[458]\tTest-mae:0.06988\n",
      "[459]\tTest-mae:0.06988\n",
      "[460]\tTest-mae:0.06986\n",
      "[461]\tTest-mae:0.06985\n",
      "[462]\tTest-mae:0.06984\n",
      "[463]\tTest-mae:0.06983\n",
      "[464]\tTest-mae:0.06983\n",
      "[465]\tTest-mae:0.06982\n",
      "[466]\tTest-mae:0.06982\n",
      "[467]\tTest-mae:0.06981\n",
      "[468]\tTest-mae:0.06980\n",
      "[469]\tTest-mae:0.06978\n",
      "[470]\tTest-mae:0.06978\n",
      "[471]\tTest-mae:0.06978\n",
      "[472]\tTest-mae:0.06977\n",
      "[473]\tTest-mae:0.06976\n",
      "[474]\tTest-mae:0.06975\n",
      "[475]\tTest-mae:0.06975\n",
      "[476]\tTest-mae:0.06974\n",
      "[477]\tTest-mae:0.06974\n",
      "[478]\tTest-mae:0.06973\n",
      "[479]\tTest-mae:0.06972\n",
      "[480]\tTest-mae:0.06971\n",
      "[481]\tTest-mae:0.06971\n",
      "[482]\tTest-mae:0.06970\n",
      "[483]\tTest-mae:0.06969\n",
      "[484]\tTest-mae:0.06969\n",
      "[485]\tTest-mae:0.06969\n",
      "[486]\tTest-mae:0.06967\n",
      "[487]\tTest-mae:0.06966\n",
      "[488]\tTest-mae:0.06966\n",
      "[489]\tTest-mae:0.06966\n",
      "[490]\tTest-mae:0.06965\n",
      "[491]\tTest-mae:0.06963\n",
      "[492]\tTest-mae:0.06963\n",
      "[493]\tTest-mae:0.06962\n",
      "[494]\tTest-mae:0.06962\n",
      "[495]\tTest-mae:0.06962\n",
      "[496]\tTest-mae:0.06962\n",
      "[497]\tTest-mae:0.06961\n",
      "[498]\tTest-mae:0.06961\n",
      "[499]\tTest-mae:0.06961\n",
      "[500]\tTest-mae:0.06960\n",
      "[501]\tTest-mae:0.06960\n",
      "[502]\tTest-mae:0.06960\n",
      "[503]\tTest-mae:0.06958\n",
      "[504]\tTest-mae:0.06958\n",
      "[505]\tTest-mae:0.06958\n",
      "[506]\tTest-mae:0.06956\n",
      "[507]\tTest-mae:0.06956\n",
      "[508]\tTest-mae:0.06955\n",
      "[509]\tTest-mae:0.06954\n",
      "[510]\tTest-mae:0.06953\n",
      "[511]\tTest-mae:0.06952\n",
      "[512]\tTest-mae:0.06951\n",
      "[513]\tTest-mae:0.06950\n",
      "[514]\tTest-mae:0.06950\n",
      "[515]\tTest-mae:0.06950\n",
      "[516]\tTest-mae:0.06950\n",
      "[517]\tTest-mae:0.06948\n",
      "[518]\tTest-mae:0.06948\n",
      "[519]\tTest-mae:0.06947\n",
      "[520]\tTest-mae:0.06947\n",
      "[521]\tTest-mae:0.06945\n",
      "[522]\tTest-mae:0.06945\n",
      "[523]\tTest-mae:0.06945\n",
      "[524]\tTest-mae:0.06944\n",
      "[525]\tTest-mae:0.06944\n",
      "[526]\tTest-mae:0.06943\n",
      "[527]\tTest-mae:0.06943\n",
      "[528]\tTest-mae:0.06943\n",
      "[529]\tTest-mae:0.06943\n",
      "[530]\tTest-mae:0.06943\n",
      "[531]\tTest-mae:0.06942\n",
      "[532]\tTest-mae:0.06941\n",
      "[533]\tTest-mae:0.06940\n",
      "[534]\tTest-mae:0.06940\n",
      "[535]\tTest-mae:0.06939\n",
      "[536]\tTest-mae:0.06939\n",
      "[537]\tTest-mae:0.06939\n",
      "[538]\tTest-mae:0.06938\n",
      "[539]\tTest-mae:0.06937\n",
      "[540]\tTest-mae:0.06937\n",
      "[541]\tTest-mae:0.06936\n",
      "[542]\tTest-mae:0.06936\n",
      "[543]\tTest-mae:0.06935\n",
      "[544]\tTest-mae:0.06935\n",
      "[545]\tTest-mae:0.06934\n",
      "[546]\tTest-mae:0.06933\n",
      "[547]\tTest-mae:0.06933\n",
      "[548]\tTest-mae:0.06932\n",
      "[549]\tTest-mae:0.06931\n",
      "[550]\tTest-mae:0.06931\n",
      "[551]\tTest-mae:0.06931\n",
      "[552]\tTest-mae:0.06930\n",
      "[553]\tTest-mae:0.06929\n",
      "[554]\tTest-mae:0.06929\n",
      "[555]\tTest-mae:0.06927\n",
      "[556]\tTest-mae:0.06928\n",
      "[557]\tTest-mae:0.06927\n",
      "[558]\tTest-mae:0.06927\n",
      "[559]\tTest-mae:0.06925\n",
      "[560]\tTest-mae:0.06925\n",
      "[561]\tTest-mae:0.06924\n",
      "[562]\tTest-mae:0.06924\n",
      "[563]\tTest-mae:0.06924\n",
      "[564]\tTest-mae:0.06923\n",
      "[565]\tTest-mae:0.06922\n",
      "[566]\tTest-mae:0.06922\n",
      "[567]\tTest-mae:0.06920\n",
      "[568]\tTest-mae:0.06920\n",
      "[569]\tTest-mae:0.06918\n",
      "[570]\tTest-mae:0.06917\n",
      "[571]\tTest-mae:0.06917\n",
      "[572]\tTest-mae:0.06916\n",
      "[573]\tTest-mae:0.06916\n",
      "[574]\tTest-mae:0.06916\n",
      "[575]\tTest-mae:0.06915\n",
      "[576]\tTest-mae:0.06914\n",
      "[577]\tTest-mae:0.06914\n",
      "[578]\tTest-mae:0.06914\n",
      "[579]\tTest-mae:0.06913\n",
      "[580]\tTest-mae:0.06913\n",
      "[581]\tTest-mae:0.06913\n",
      "[582]\tTest-mae:0.06912\n",
      "[583]\tTest-mae:0.06912\n",
      "[584]\tTest-mae:0.06911\n",
      "[585]\tTest-mae:0.06910\n",
      "[586]\tTest-mae:0.06911\n",
      "[587]\tTest-mae:0.06910\n",
      "[588]\tTest-mae:0.06910\n",
      "[589]\tTest-mae:0.06909\n",
      "[590]\tTest-mae:0.06908\n",
      "[591]\tTest-mae:0.06908\n",
      "[592]\tTest-mae:0.06908\n",
      "[593]\tTest-mae:0.06908\n",
      "[594]\tTest-mae:0.06907\n",
      "[595]\tTest-mae:0.06907\n",
      "[596]\tTest-mae:0.06907\n",
      "[597]\tTest-mae:0.06907\n",
      "[598]\tTest-mae:0.06907\n",
      "[599]\tTest-mae:0.06907\n",
      "[600]\tTest-mae:0.06907\n",
      "[601]\tTest-mae:0.06906\n",
      "[602]\tTest-mae:0.06906\n",
      "[603]\tTest-mae:0.06905\n",
      "[604]\tTest-mae:0.06904\n",
      "[605]\tTest-mae:0.06904\n",
      "[606]\tTest-mae:0.06901\n",
      "[607]\tTest-mae:0.06901\n",
      "[608]\tTest-mae:0.06901\n",
      "[609]\tTest-mae:0.06900\n",
      "[610]\tTest-mae:0.06899\n",
      "[611]\tTest-mae:0.06899\n",
      "[612]\tTest-mae:0.06898\n",
      "[613]\tTest-mae:0.06897\n",
      "[614]\tTest-mae:0.06897\n",
      "[615]\tTest-mae:0.06896\n",
      "[616]\tTest-mae:0.06896\n",
      "[617]\tTest-mae:0.06896\n",
      "[618]\tTest-mae:0.06896\n",
      "[619]\tTest-mae:0.06895\n",
      "[620]\tTest-mae:0.06895\n",
      "[621]\tTest-mae:0.06894\n",
      "[622]\tTest-mae:0.06894\n",
      "[623]\tTest-mae:0.06894\n",
      "[624]\tTest-mae:0.06894\n",
      "[625]\tTest-mae:0.06893\n",
      "[626]\tTest-mae:0.06892\n",
      "[627]\tTest-mae:0.06890\n",
      "[628]\tTest-mae:0.06889\n",
      "[629]\tTest-mae:0.06889\n",
      "[630]\tTest-mae:0.06889\n",
      "[631]\tTest-mae:0.06888\n",
      "[632]\tTest-mae:0.06888\n",
      "[633]\tTest-mae:0.06887\n",
      "[634]\tTest-mae:0.06887\n",
      "[635]\tTest-mae:0.06886\n",
      "[636]\tTest-mae:0.06886\n",
      "[637]\tTest-mae:0.06886\n",
      "[638]\tTest-mae:0.06886\n",
      "[639]\tTest-mae:0.06885\n",
      "[640]\tTest-mae:0.06885\n",
      "[641]\tTest-mae:0.06885\n",
      "[642]\tTest-mae:0.06884\n",
      "[643]\tTest-mae:0.06882\n",
      "[644]\tTest-mae:0.06882\n",
      "[645]\tTest-mae:0.06881\n",
      "[646]\tTest-mae:0.06881\n",
      "[647]\tTest-mae:0.06880\n",
      "[648]\tTest-mae:0.06880\n",
      "[649]\tTest-mae:0.06880\n",
      "[650]\tTest-mae:0.06880\n",
      "[651]\tTest-mae:0.06879\n",
      "[652]\tTest-mae:0.06879\n",
      "[653]\tTest-mae:0.06879\n",
      "[654]\tTest-mae:0.06879\n",
      "[655]\tTest-mae:0.06878\n",
      "[656]\tTest-mae:0.06878\n",
      "[657]\tTest-mae:0.06877\n",
      "[658]\tTest-mae:0.06877\n",
      "[659]\tTest-mae:0.06876\n",
      "[660]\tTest-mae:0.06877\n",
      "[661]\tTest-mae:0.06876\n",
      "[662]\tTest-mae:0.06876\n",
      "[663]\tTest-mae:0.06875\n",
      "[664]\tTest-mae:0.06875\n",
      "[665]\tTest-mae:0.06875\n",
      "[666]\tTest-mae:0.06874\n",
      "[667]\tTest-mae:0.06874\n",
      "[668]\tTest-mae:0.06873\n",
      "[669]\tTest-mae:0.06872\n",
      "[670]\tTest-mae:0.06872\n",
      "[671]\tTest-mae:0.06872\n",
      "[672]\tTest-mae:0.06872\n",
      "[673]\tTest-mae:0.06871\n",
      "[674]\tTest-mae:0.06871\n",
      "[675]\tTest-mae:0.06871\n",
      "[676]\tTest-mae:0.06871\n",
      "[677]\tTest-mae:0.06870\n",
      "[678]\tTest-mae:0.06869\n",
      "[679]\tTest-mae:0.06868\n",
      "[680]\tTest-mae:0.06868\n",
      "[681]\tTest-mae:0.06867\n",
      "[682]\tTest-mae:0.06867\n",
      "[683]\tTest-mae:0.06867\n",
      "[684]\tTest-mae:0.06867\n",
      "[685]\tTest-mae:0.06866\n",
      "[686]\tTest-mae:0.06866\n",
      "[687]\tTest-mae:0.06866\n",
      "[688]\tTest-mae:0.06866\n",
      "[689]\tTest-mae:0.06866\n",
      "[690]\tTest-mae:0.06865\n",
      "[691]\tTest-mae:0.06864\n",
      "[692]\tTest-mae:0.06864\n",
      "[693]\tTest-mae:0.06863\n",
      "[694]\tTest-mae:0.06863\n",
      "[695]\tTest-mae:0.06863\n",
      "[696]\tTest-mae:0.06863\n",
      "[697]\tTest-mae:0.06862\n",
      "[698]\tTest-mae:0.06862\n",
      "[699]\tTest-mae:0.06861\n",
      "[700]\tTest-mae:0.06861\n",
      "[701]\tTest-mae:0.06861\n",
      "[702]\tTest-mae:0.06860\n",
      "[703]\tTest-mae:0.06860\n",
      "[704]\tTest-mae:0.06860\n",
      "[705]\tTest-mae:0.06859\n",
      "[706]\tTest-mae:0.06859\n",
      "[707]\tTest-mae:0.06859\n",
      "[708]\tTest-mae:0.06858\n",
      "[709]\tTest-mae:0.06857\n",
      "[710]\tTest-mae:0.06857\n",
      "[711]\tTest-mae:0.06857\n",
      "[712]\tTest-mae:0.06857\n",
      "[713]\tTest-mae:0.06856\n",
      "[714]\tTest-mae:0.06856\n",
      "[715]\tTest-mae:0.06855\n",
      "[716]\tTest-mae:0.06855\n",
      "[717]\tTest-mae:0.06855\n",
      "[718]\tTest-mae:0.06855\n",
      "[719]\tTest-mae:0.06854\n",
      "[720]\tTest-mae:0.06854\n",
      "[721]\tTest-mae:0.06854\n",
      "[722]\tTest-mae:0.06853\n",
      "[723]\tTest-mae:0.06853\n",
      "[724]\tTest-mae:0.06852\n",
      "[725]\tTest-mae:0.06852\n",
      "[726]\tTest-mae:0.06852\n",
      "[727]\tTest-mae:0.06852\n",
      "[728]\tTest-mae:0.06851\n",
      "[729]\tTest-mae:0.06851\n",
      "[730]\tTest-mae:0.06851\n",
      "[731]\tTest-mae:0.06850\n",
      "[732]\tTest-mae:0.06850\n",
      "[733]\tTest-mae:0.06850\n",
      "[734]\tTest-mae:0.06849\n",
      "[735]\tTest-mae:0.06848\n",
      "[736]\tTest-mae:0.06848\n",
      "[737]\tTest-mae:0.06848\n",
      "[738]\tTest-mae:0.06848\n",
      "[739]\tTest-mae:0.06848\n",
      "[740]\tTest-mae:0.06848\n",
      "[741]\tTest-mae:0.06848\n",
      "[742]\tTest-mae:0.06847\n",
      "[743]\tTest-mae:0.06846\n",
      "[744]\tTest-mae:0.06846\n",
      "[745]\tTest-mae:0.06845\n",
      "[746]\tTest-mae:0.06844\n",
      "[747]\tTest-mae:0.06844\n",
      "[748]\tTest-mae:0.06844\n",
      "[749]\tTest-mae:0.06844\n",
      "[750]\tTest-mae:0.06843\n",
      "[751]\tTest-mae:0.06842\n",
      "[752]\tTest-mae:0.06842\n",
      "[753]\tTest-mae:0.06842\n",
      "[754]\tTest-mae:0.06842\n",
      "[755]\tTest-mae:0.06841\n",
      "[756]\tTest-mae:0.06841\n",
      "[757]\tTest-mae:0.06841\n",
      "[758]\tTest-mae:0.06840\n",
      "[759]\tTest-mae:0.06840\n",
      "[760]\tTest-mae:0.06840\n",
      "[761]\tTest-mae:0.06840\n",
      "[762]\tTest-mae:0.06840\n",
      "[763]\tTest-mae:0.06840\n",
      "[764]\tTest-mae:0.06839\n",
      "[765]\tTest-mae:0.06839\n",
      "[766]\tTest-mae:0.06838\n",
      "[767]\tTest-mae:0.06838\n",
      "[768]\tTest-mae:0.06838\n",
      "[769]\tTest-mae:0.06838\n",
      "[770]\tTest-mae:0.06838\n",
      "[771]\tTest-mae:0.06838\n",
      "[772]\tTest-mae:0.06837\n",
      "[773]\tTest-mae:0.06837\n",
      "[774]\tTest-mae:0.06837\n",
      "[775]\tTest-mae:0.06837\n",
      "[776]\tTest-mae:0.06837\n",
      "[777]\tTest-mae:0.06837\n",
      "[778]\tTest-mae:0.06837\n",
      "[779]\tTest-mae:0.06837\n",
      "[780]\tTest-mae:0.06836\n",
      "[781]\tTest-mae:0.06836\n",
      "[782]\tTest-mae:0.06836\n",
      "[783]\tTest-mae:0.06836\n",
      "[784]\tTest-mae:0.06835\n",
      "[785]\tTest-mae:0.06835\n",
      "[786]\tTest-mae:0.06835\n",
      "[787]\tTest-mae:0.06835\n",
      "[788]\tTest-mae:0.06835\n",
      "[789]\tTest-mae:0.06835\n",
      "[790]\tTest-mae:0.06834\n",
      "[791]\tTest-mae:0.06834\n",
      "[792]\tTest-mae:0.06834\n",
      "[793]\tTest-mae:0.06833\n",
      "[794]\tTest-mae:0.06833\n",
      "[795]\tTest-mae:0.06833\n",
      "[796]\tTest-mae:0.06832\n",
      "[797]\tTest-mae:0.06832\n",
      "[798]\tTest-mae:0.06832\n",
      "[799]\tTest-mae:0.06832\n",
      "[800]\tTest-mae:0.06832\n",
      "[801]\tTest-mae:0.06831\n",
      "[802]\tTest-mae:0.06831\n",
      "[803]\tTest-mae:0.06831\n",
      "[804]\tTest-mae:0.06831\n",
      "[805]\tTest-mae:0.06831\n",
      "[806]\tTest-mae:0.06831\n",
      "[807]\tTest-mae:0.06830\n",
      "[808]\tTest-mae:0.06830\n",
      "[809]\tTest-mae:0.06829\n",
      "[810]\tTest-mae:0.06829\n",
      "[811]\tTest-mae:0.06829\n",
      "[812]\tTest-mae:0.06828\n",
      "[813]\tTest-mae:0.06828\n",
      "[814]\tTest-mae:0.06828\n",
      "[815]\tTest-mae:0.06828\n",
      "[816]\tTest-mae:0.06827\n",
      "[817]\tTest-mae:0.06827\n",
      "[818]\tTest-mae:0.06827\n",
      "[819]\tTest-mae:0.06827\n",
      "[820]\tTest-mae:0.06826\n",
      "[821]\tTest-mae:0.06826\n",
      "[822]\tTest-mae:0.06825\n",
      "[823]\tTest-mae:0.06825\n",
      "[824]\tTest-mae:0.06825\n",
      "[825]\tTest-mae:0.06825\n",
      "[826]\tTest-mae:0.06825\n",
      "[827]\tTest-mae:0.06824\n",
      "[828]\tTest-mae:0.06824\n",
      "[829]\tTest-mae:0.06824\n",
      "[830]\tTest-mae:0.06823\n",
      "[831]\tTest-mae:0.06823\n",
      "[832]\tTest-mae:0.06823\n",
      "[833]\tTest-mae:0.06823\n",
      "[834]\tTest-mae:0.06822\n",
      "[835]\tTest-mae:0.06822\n",
      "[836]\tTest-mae:0.06822\n",
      "[837]\tTest-mae:0.06821\n",
      "[838]\tTest-mae:0.06821\n",
      "[839]\tTest-mae:0.06821\n",
      "[840]\tTest-mae:0.06821\n",
      "[841]\tTest-mae:0.06820\n",
      "[842]\tTest-mae:0.06820\n",
      "[843]\tTest-mae:0.06820\n",
      "[844]\tTest-mae:0.06820\n",
      "[845]\tTest-mae:0.06819\n",
      "[846]\tTest-mae:0.06819\n",
      "[847]\tTest-mae:0.06819\n",
      "[848]\tTest-mae:0.06819\n",
      "[849]\tTest-mae:0.06819\n",
      "[850]\tTest-mae:0.06819\n",
      "[851]\tTest-mae:0.06819\n",
      "[852]\tTest-mae:0.06819\n",
      "[853]\tTest-mae:0.06819\n",
      "[854]\tTest-mae:0.06819\n",
      "[855]\tTest-mae:0.06818\n",
      "[856]\tTest-mae:0.06818\n",
      "[857]\tTest-mae:0.06818\n",
      "[858]\tTest-mae:0.06818\n",
      "[859]\tTest-mae:0.06817\n",
      "[860]\tTest-mae:0.06817\n",
      "[861]\tTest-mae:0.06817\n",
      "[862]\tTest-mae:0.06817\n",
      "[863]\tTest-mae:0.06817\n",
      "[864]\tTest-mae:0.06817\n",
      "[865]\tTest-mae:0.06816\n",
      "[866]\tTest-mae:0.06816\n",
      "[867]\tTest-mae:0.06816\n",
      "[868]\tTest-mae:0.06815\n",
      "[869]\tTest-mae:0.06815\n",
      "[870]\tTest-mae:0.06815\n",
      "[871]\tTest-mae:0.06815\n",
      "[872]\tTest-mae:0.06814\n",
      "[873]\tTest-mae:0.06814\n",
      "[874]\tTest-mae:0.06814\n",
      "[875]\tTest-mae:0.06814\n",
      "[876]\tTest-mae:0.06814\n",
      "[877]\tTest-mae:0.06814\n",
      "[878]\tTest-mae:0.06814\n",
      "[879]\tTest-mae:0.06814\n",
      "[880]\tTest-mae:0.06814\n",
      "[881]\tTest-mae:0.06813\n",
      "[882]\tTest-mae:0.06813\n",
      "[883]\tTest-mae:0.06813\n",
      "[884]\tTest-mae:0.06812\n",
      "[885]\tTest-mae:0.06812\n",
      "[886]\tTest-mae:0.06812\n",
      "[887]\tTest-mae:0.06812\n",
      "[888]\tTest-mae:0.06812\n",
      "[889]\tTest-mae:0.06811\n",
      "[890]\tTest-mae:0.06811\n",
      "[891]\tTest-mae:0.06811\n",
      "[892]\tTest-mae:0.06810\n",
      "[893]\tTest-mae:0.06810\n",
      "[894]\tTest-mae:0.06810\n",
      "[895]\tTest-mae:0.06810\n",
      "[896]\tTest-mae:0.06810\n",
      "[897]\tTest-mae:0.06809\n",
      "[898]\tTest-mae:0.06809\n",
      "[899]\tTest-mae:0.06808\n",
      "[900]\tTest-mae:0.06808\n",
      "[901]\tTest-mae:0.06808\n",
      "[902]\tTest-mae:0.06808\n",
      "[903]\tTest-mae:0.06808\n",
      "[904]\tTest-mae:0.06807\n",
      "[905]\tTest-mae:0.06807\n",
      "[906]\tTest-mae:0.06807\n",
      "[907]\tTest-mae:0.06807\n",
      "[908]\tTest-mae:0.06807\n",
      "[909]\tTest-mae:0.06807\n",
      "[910]\tTest-mae:0.06807\n",
      "[911]\tTest-mae:0.06806\n",
      "[912]\tTest-mae:0.06806\n",
      "[913]\tTest-mae:0.06806\n",
      "[914]\tTest-mae:0.06806\n",
      "[915]\tTest-mae:0.06805\n",
      "[916]\tTest-mae:0.06805\n",
      "[917]\tTest-mae:0.06805\n",
      "[918]\tTest-mae:0.06805\n",
      "[919]\tTest-mae:0.06805\n",
      "[920]\tTest-mae:0.06804\n",
      "[921]\tTest-mae:0.06804\n",
      "[922]\tTest-mae:0.06804\n",
      "[923]\tTest-mae:0.06804\n",
      "[924]\tTest-mae:0.06804\n",
      "[925]\tTest-mae:0.06804\n",
      "[926]\tTest-mae:0.06803\n",
      "[927]\tTest-mae:0.06803\n",
      "[928]\tTest-mae:0.06803\n",
      "[929]\tTest-mae:0.06803\n",
      "[930]\tTest-mae:0.06802\n",
      "[931]\tTest-mae:0.06802\n",
      "[932]\tTest-mae:0.06802\n",
      "[933]\tTest-mae:0.06801\n",
      "[934]\tTest-mae:0.06801\n",
      "[935]\tTest-mae:0.06801\n",
      "[936]\tTest-mae:0.06801\n",
      "[937]\tTest-mae:0.06801\n",
      "[938]\tTest-mae:0.06800\n",
      "[939]\tTest-mae:0.06800\n",
      "[940]\tTest-mae:0.06800\n",
      "[941]\tTest-mae:0.06800\n",
      "[942]\tTest-mae:0.06800\n",
      "[943]\tTest-mae:0.06800\n",
      "[944]\tTest-mae:0.06800\n",
      "[945]\tTest-mae:0.06799\n",
      "[946]\tTest-mae:0.06799\n",
      "[947]\tTest-mae:0.06799\n",
      "[948]\tTest-mae:0.06799\n",
      "[949]\tTest-mae:0.06799\n",
      "[950]\tTest-mae:0.06799\n",
      "[951]\tTest-mae:0.06799\n",
      "[952]\tTest-mae:0.06799\n",
      "[953]\tTest-mae:0.06798\n",
      "[954]\tTest-mae:0.06798\n",
      "[955]\tTest-mae:0.06798\n",
      "[956]\tTest-mae:0.06798\n",
      "[957]\tTest-mae:0.06798\n",
      "[958]\tTest-mae:0.06798\n",
      "[959]\tTest-mae:0.06798\n",
      "[960]\tTest-mae:0.06798\n",
      "[961]\tTest-mae:0.06797\n",
      "[962]\tTest-mae:0.06797\n",
      "[963]\tTest-mae:0.06797\n",
      "[964]\tTest-mae:0.06797\n",
      "[965]\tTest-mae:0.06796\n",
      "[966]\tTest-mae:0.06796\n",
      "[967]\tTest-mae:0.06796\n",
      "[968]\tTest-mae:0.06796\n",
      "[969]\tTest-mae:0.06796\n",
      "[970]\tTest-mae:0.06795\n",
      "[971]\tTest-mae:0.06795\n",
      "[972]\tTest-mae:0.06795\n",
      "[973]\tTest-mae:0.06795\n",
      "[974]\tTest-mae:0.06795\n",
      "[975]\tTest-mae:0.06794\n",
      "[976]\tTest-mae:0.06794\n",
      "[977]\tTest-mae:0.06794\n",
      "[978]\tTest-mae:0.06794\n",
      "[979]\tTest-mae:0.06793\n",
      "[980]\tTest-mae:0.06793\n",
      "[981]\tTest-mae:0.06793\n",
      "[982]\tTest-mae:0.06793\n",
      "[983]\tTest-mae:0.06793\n",
      "[984]\tTest-mae:0.06793\n",
      "[985]\tTest-mae:0.06793\n",
      "[986]\tTest-mae:0.06792\n",
      "[987]\tTest-mae:0.06792\n",
      "[988]\tTest-mae:0.06792\n",
      "[989]\tTest-mae:0.06792\n",
      "[990]\tTest-mae:0.06792\n",
      "[991]\tTest-mae:0.06792\n",
      "[992]\tTest-mae:0.06792\n",
      "[993]\tTest-mae:0.06791\n",
      "[994]\tTest-mae:0.06791\n",
      "[995]\tTest-mae:0.06791\n",
      "[996]\tTest-mae:0.06791\n",
      "[997]\tTest-mae:0.06791\n",
      "[998]\tTest-mae:0.06791\n",
      "[999]\tTest-mae:0.06790\n",
      "Best MAE: 0.06790 with 1000 rounds\n",
      "CV with max_depth=11, min_child_weight=8\n",
      "[21:07:18] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:07:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:07:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:07:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:07:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.07123360000000001 for 999 rounds\n",
      "CV with max_depth=11, min_child_weight=9\n",
      "[21:19:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:19:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:19:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:19:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:19:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.0713952 for 999 rounds\n",
      "CV with max_depth=11, min_child_weight=10\n",
      "[21:31:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:31:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:31:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:31:20] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:31:20] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.07139340000000001 for 999 rounds\n",
      "CV with max_depth=12, min_child_weight=8\n",
      "[21:43:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:43:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:43:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:43:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:43:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.071394 for 999 rounds\n",
      "CV with max_depth=12, min_child_weight=9\n",
      "[21:56:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:56:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:56:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:56:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:56:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.0715162 for 999 rounds\n",
      "CV with max_depth=12, min_child_weight=10\n",
      "[22:10:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.07139619999999999 for 999 rounds\n",
      "CV with max_depth=13, min_child_weight=8\n",
      "[22:23:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:23:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:23:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:23:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:23:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.07150719999999999 for 999 rounds\n",
      "CV with max_depth=13, min_child_weight=9\n",
      "[22:38:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:38:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:38:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:38:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:38:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.07143519999999999 for 999 rounds\n",
      "CV with max_depth=13, min_child_weight=10\n",
      "[22:53:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:53:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:53:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:53:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:53:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.07160419999999999 for 999 rounds\n",
      "CV with max_depth=14, min_child_weight=8\n",
      "[23:08:38] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:08:38] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:08:38] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:08:39] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:08:39] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.071964 for 999 rounds\n",
      "CV with max_depth=14, min_child_weight=9\n",
      "[23:24:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:24:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:24:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:24:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:24:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.0718224 for 999 rounds\n",
      "CV with max_depth=14, min_child_weight=10\n",
      "[23:41:02] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:41:02] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:41:02] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:41:02] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:41:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.0717 for 999 rounds\n",
      "Best params: 11, 8, MAE: 0.07123360000000001\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "[23:57:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:57:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:57:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:57:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:57:07] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.06990800000000001 for 999 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "[00:14:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:14:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:14:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:14:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:14:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.0699644 for 999 rounds\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "[00:29:37] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:29:37] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:29:37] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:29:37] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:29:38] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.0698928 for 999 rounds\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "[00:46:24] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:46:24] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:46:25] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:46:25] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:46:25] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.06995200000000001 for 999 rounds\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "[01:01:46] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:01:46] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:01:46] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:01:46] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:01:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.0700904 for 999 rounds\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "[01:18:24] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:18:25] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:18:25] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:18:25] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:18:25] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.0700846 for 999 rounds\n",
      "CV with subsample=0.6, colsample=0.9\n",
      "[01:33:35] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:33:35] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:33:36] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:33:36] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:33:36] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.0706686 for 999 rounds\n",
      "CV with subsample=0.6, colsample=0.8\n",
      "[01:49:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:49:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:49:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:49:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:49:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.0707654 for 999 rounds\n",
      "Best params: 0.8, 0.9, MAE: 0.0698928\n",
      "CV with eta=0.1\n",
      "[02:04:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:04:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:04:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:04:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:04:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.07076040000000001 for 999 rounds\n",
      "\n",
      "CV with eta=0.05\n",
      "[02:20:13] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:20:13] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:20:13] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:20:13] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:20:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.06995200000000001 for 999 rounds\n",
      "\n",
      "CV with eta=0.01\n",
      "[02:35:34] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:35:34] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:35:34] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:35:35] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:35:35] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.07468899999999999 for 999 rounds\n",
      "\n",
      "Best params: 0.05, MAE: 0.06995200000000001\n",
      "my new params are: {'colsample_bytree': 0.8, 'max_depth': 11, 'min_child_weight': 8, 'eval_metric': 'mae', 'subsample': 0.8, 'colsample': 0.9, 'eta': 0.05}\n",
      "[02:51:37] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:51:37] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:51:37] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:51:37] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:51:38] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:07:08] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tTest-mae:0.31447\n",
      "[1]\tTest-mae:0.30150\n",
      "[2]\tTest-mae:0.28922\n",
      "[3]\tTest-mae:0.27760\n",
      "[4]\tTest-mae:0.26652\n",
      "[5]\tTest-mae:0.25598\n",
      "[6]\tTest-mae:0.24617\n",
      "[7]\tTest-mae:0.23678\n",
      "[8]\tTest-mae:0.22813\n",
      "[9]\tTest-mae:0.21979\n",
      "[10]\tTest-mae:0.21190\n",
      "[11]\tTest-mae:0.20448\n",
      "[12]\tTest-mae:0.19746\n",
      "[13]\tTest-mae:0.19079\n",
      "[14]\tTest-mae:0.18459\n",
      "[15]\tTest-mae:0.17864\n",
      "[16]\tTest-mae:0.17308\n",
      "[17]\tTest-mae:0.16792\n",
      "[18]\tTest-mae:0.16290\n",
      "[19]\tTest-mae:0.15824\n",
      "[20]\tTest-mae:0.15384\n",
      "[21]\tTest-mae:0.14966\n",
      "[22]\tTest-mae:0.14574\n",
      "[23]\tTest-mae:0.14199\n",
      "[24]\tTest-mae:0.13851\n",
      "[25]\tTest-mae:0.13524\n",
      "[26]\tTest-mae:0.13213\n",
      "[27]\tTest-mae:0.12930\n",
      "[28]\tTest-mae:0.12652\n",
      "[29]\tTest-mae:0.12395\n",
      "[30]\tTest-mae:0.12147\n",
      "[31]\tTest-mae:0.11916\n",
      "[32]\tTest-mae:0.11700\n",
      "[33]\tTest-mae:0.11498\n",
      "[34]\tTest-mae:0.11302\n",
      "[35]\tTest-mae:0.11121\n",
      "[36]\tTest-mae:0.10961\n",
      "[37]\tTest-mae:0.10801\n",
      "[38]\tTest-mae:0.10651\n",
      "[39]\tTest-mae:0.10511\n",
      "[40]\tTest-mae:0.10376\n",
      "[41]\tTest-mae:0.10245\n",
      "[42]\tTest-mae:0.10122\n",
      "[43]\tTest-mae:0.10011\n",
      "[44]\tTest-mae:0.09906\n",
      "[45]\tTest-mae:0.09800\n",
      "[46]\tTest-mae:0.09702\n",
      "[47]\tTest-mae:0.09611\n",
      "[48]\tTest-mae:0.09529\n",
      "[49]\tTest-mae:0.09451\n",
      "[50]\tTest-mae:0.09379\n",
      "[51]\tTest-mae:0.09301\n",
      "[52]\tTest-mae:0.09232\n",
      "[53]\tTest-mae:0.09166\n",
      "[54]\tTest-mae:0.09107\n",
      "[55]\tTest-mae:0.09040\n",
      "[56]\tTest-mae:0.08985\n",
      "[57]\tTest-mae:0.08934\n",
      "[58]\tTest-mae:0.08883\n",
      "[59]\tTest-mae:0.08829\n",
      "[60]\tTest-mae:0.08785\n",
      "[61]\tTest-mae:0.08738\n",
      "[62]\tTest-mae:0.08691\n",
      "[63]\tTest-mae:0.08658\n",
      "[64]\tTest-mae:0.08620\n",
      "[65]\tTest-mae:0.08582\n",
      "[66]\tTest-mae:0.08547\n",
      "[67]\tTest-mae:0.08514\n",
      "[68]\tTest-mae:0.08481\n",
      "[69]\tTest-mae:0.08452\n",
      "[70]\tTest-mae:0.08423\n",
      "[71]\tTest-mae:0.08398\n",
      "[72]\tTest-mae:0.08371\n",
      "[73]\tTest-mae:0.08348\n",
      "[74]\tTest-mae:0.08327\n",
      "[75]\tTest-mae:0.08303\n",
      "[76]\tTest-mae:0.08277\n",
      "[77]\tTest-mae:0.08260\n",
      "[78]\tTest-mae:0.08235\n",
      "[79]\tTest-mae:0.08213\n",
      "[80]\tTest-mae:0.08195\n",
      "[81]\tTest-mae:0.08172\n",
      "[82]\tTest-mae:0.08159\n",
      "[83]\tTest-mae:0.08142\n",
      "[84]\tTest-mae:0.08124\n",
      "[85]\tTest-mae:0.08105\n",
      "[86]\tTest-mae:0.08086\n",
      "[87]\tTest-mae:0.08066\n",
      "[88]\tTest-mae:0.08045\n",
      "[89]\tTest-mae:0.08028\n",
      "[90]\tTest-mae:0.08019\n",
      "[91]\tTest-mae:0.08006\n",
      "[92]\tTest-mae:0.07993\n",
      "[93]\tTest-mae:0.07981\n",
      "[94]\tTest-mae:0.07968\n",
      "[95]\tTest-mae:0.07956\n",
      "[96]\tTest-mae:0.07941\n",
      "[97]\tTest-mae:0.07925\n",
      "[98]\tTest-mae:0.07913\n",
      "[99]\tTest-mae:0.07900\n",
      "[100]\tTest-mae:0.07888\n",
      "[101]\tTest-mae:0.07874\n",
      "[102]\tTest-mae:0.07865\n",
      "[103]\tTest-mae:0.07861\n",
      "[104]\tTest-mae:0.07852\n",
      "[105]\tTest-mae:0.07843\n",
      "[106]\tTest-mae:0.07834\n",
      "[107]\tTest-mae:0.07825\n",
      "[108]\tTest-mae:0.07819\n",
      "[109]\tTest-mae:0.07809\n",
      "[110]\tTest-mae:0.07804\n",
      "[111]\tTest-mae:0.07792\n",
      "[112]\tTest-mae:0.07785\n",
      "[113]\tTest-mae:0.07776\n",
      "[114]\tTest-mae:0.07765\n",
      "[115]\tTest-mae:0.07761\n",
      "[116]\tTest-mae:0.07756\n",
      "[117]\tTest-mae:0.07748\n",
      "[118]\tTest-mae:0.07740\n",
      "[119]\tTest-mae:0.07729\n",
      "[120]\tTest-mae:0.07723\n",
      "[121]\tTest-mae:0.07719\n",
      "[122]\tTest-mae:0.07711\n",
      "[123]\tTest-mae:0.07704\n",
      "[124]\tTest-mae:0.07693\n",
      "[125]\tTest-mae:0.07680\n",
      "[126]\tTest-mae:0.07677\n",
      "[127]\tTest-mae:0.07675\n",
      "[128]\tTest-mae:0.07669\n",
      "[129]\tTest-mae:0.07663\n",
      "[130]\tTest-mae:0.07658\n",
      "[131]\tTest-mae:0.07649\n",
      "[132]\tTest-mae:0.07646\n",
      "[133]\tTest-mae:0.07640\n",
      "[134]\tTest-mae:0.07635\n",
      "[135]\tTest-mae:0.07632\n",
      "[136]\tTest-mae:0.07621\n",
      "[137]\tTest-mae:0.07617\n",
      "[138]\tTest-mae:0.07614\n",
      "[139]\tTest-mae:0.07608\n",
      "[140]\tTest-mae:0.07603\n",
      "[141]\tTest-mae:0.07596\n",
      "[142]\tTest-mae:0.07590\n",
      "[143]\tTest-mae:0.07583\n",
      "[144]\tTest-mae:0.07573\n",
      "[145]\tTest-mae:0.07569\n",
      "[146]\tTest-mae:0.07562\n",
      "[147]\tTest-mae:0.07551\n",
      "[148]\tTest-mae:0.07550\n",
      "[149]\tTest-mae:0.07542\n",
      "[150]\tTest-mae:0.07537\n",
      "[151]\tTest-mae:0.07534\n",
      "[152]\tTest-mae:0.07531\n",
      "[153]\tTest-mae:0.07526\n",
      "[154]\tTest-mae:0.07520\n",
      "[155]\tTest-mae:0.07518\n",
      "[156]\tTest-mae:0.07515\n",
      "[157]\tTest-mae:0.07514\n",
      "[158]\tTest-mae:0.07509\n",
      "[159]\tTest-mae:0.07504\n",
      "[160]\tTest-mae:0.07497\n",
      "[161]\tTest-mae:0.07494\n",
      "[162]\tTest-mae:0.07487\n",
      "[163]\tTest-mae:0.07484\n",
      "[164]\tTest-mae:0.07483\n",
      "[165]\tTest-mae:0.07480\n",
      "[166]\tTest-mae:0.07476\n",
      "[167]\tTest-mae:0.07475\n",
      "[168]\tTest-mae:0.07470\n",
      "[169]\tTest-mae:0.07464\n",
      "[170]\tTest-mae:0.07458\n",
      "[171]\tTest-mae:0.07454\n",
      "[172]\tTest-mae:0.07450\n",
      "[173]\tTest-mae:0.07448\n",
      "[174]\tTest-mae:0.07445\n",
      "[175]\tTest-mae:0.07441\n",
      "[176]\tTest-mae:0.07439\n",
      "[177]\tTest-mae:0.07437\n",
      "[178]\tTest-mae:0.07435\n",
      "[179]\tTest-mae:0.07433\n",
      "[180]\tTest-mae:0.07432\n",
      "[181]\tTest-mae:0.07428\n",
      "[182]\tTest-mae:0.07422\n",
      "[183]\tTest-mae:0.07421\n",
      "[184]\tTest-mae:0.07419\n",
      "[185]\tTest-mae:0.07418\n",
      "[186]\tTest-mae:0.07414\n",
      "[187]\tTest-mae:0.07407\n",
      "[188]\tTest-mae:0.07405\n",
      "[189]\tTest-mae:0.07401\n",
      "[190]\tTest-mae:0.07398\n",
      "[191]\tTest-mae:0.07397\n",
      "[192]\tTest-mae:0.07394\n",
      "[193]\tTest-mae:0.07393\n",
      "[194]\tTest-mae:0.07390\n",
      "[195]\tTest-mae:0.07389\n",
      "[196]\tTest-mae:0.07386\n",
      "[197]\tTest-mae:0.07383\n",
      "[198]\tTest-mae:0.07380\n",
      "[199]\tTest-mae:0.07375\n",
      "[200]\tTest-mae:0.07373\n",
      "[201]\tTest-mae:0.07367\n",
      "[202]\tTest-mae:0.07366\n",
      "[203]\tTest-mae:0.07365\n",
      "[204]\tTest-mae:0.07362\n",
      "[205]\tTest-mae:0.07361\n",
      "[206]\tTest-mae:0.07355\n",
      "[207]\tTest-mae:0.07354\n",
      "[208]\tTest-mae:0.07353\n",
      "[209]\tTest-mae:0.07350\n",
      "[210]\tTest-mae:0.07348\n",
      "[211]\tTest-mae:0.07348\n",
      "[212]\tTest-mae:0.07347\n",
      "[213]\tTest-mae:0.07344\n",
      "[214]\tTest-mae:0.07339\n",
      "[215]\tTest-mae:0.07337\n",
      "[216]\tTest-mae:0.07335\n",
      "[217]\tTest-mae:0.07333\n",
      "[218]\tTest-mae:0.07329\n",
      "[219]\tTest-mae:0.07324\n",
      "[220]\tTest-mae:0.07322\n",
      "[221]\tTest-mae:0.07322\n",
      "[222]\tTest-mae:0.07320\n",
      "[223]\tTest-mae:0.07315\n",
      "[224]\tTest-mae:0.07310\n",
      "[225]\tTest-mae:0.07308\n",
      "[226]\tTest-mae:0.07303\n",
      "[227]\tTest-mae:0.07302\n",
      "[228]\tTest-mae:0.07301\n",
      "[229]\tTest-mae:0.07296\n",
      "[230]\tTest-mae:0.07294\n",
      "[231]\tTest-mae:0.07292\n",
      "[232]\tTest-mae:0.07290\n",
      "[233]\tTest-mae:0.07288\n",
      "[234]\tTest-mae:0.07285\n",
      "[235]\tTest-mae:0.07284\n",
      "[236]\tTest-mae:0.07282\n",
      "[237]\tTest-mae:0.07279\n",
      "[238]\tTest-mae:0.07278\n",
      "[239]\tTest-mae:0.07274\n",
      "[240]\tTest-mae:0.07268\n",
      "[241]\tTest-mae:0.07265\n",
      "[242]\tTest-mae:0.07263\n",
      "[243]\tTest-mae:0.07262\n",
      "[244]\tTest-mae:0.07259\n",
      "[245]\tTest-mae:0.07259\n",
      "[246]\tTest-mae:0.07256\n",
      "[247]\tTest-mae:0.07256\n",
      "[248]\tTest-mae:0.07252\n",
      "[249]\tTest-mae:0.07248\n",
      "[250]\tTest-mae:0.07244\n",
      "[251]\tTest-mae:0.07243\n",
      "[252]\tTest-mae:0.07241\n",
      "[253]\tTest-mae:0.07239\n",
      "[254]\tTest-mae:0.07238\n",
      "[255]\tTest-mae:0.07234\n",
      "[256]\tTest-mae:0.07234\n",
      "[257]\tTest-mae:0.07229\n",
      "[258]\tTest-mae:0.07226\n",
      "[259]\tTest-mae:0.07220\n",
      "[260]\tTest-mae:0.07219\n",
      "[261]\tTest-mae:0.07215\n",
      "[262]\tTest-mae:0.07210\n",
      "[263]\tTest-mae:0.07209\n",
      "[264]\tTest-mae:0.07207\n",
      "[265]\tTest-mae:0.07207\n",
      "[266]\tTest-mae:0.07204\n",
      "[267]\tTest-mae:0.07202\n",
      "[268]\tTest-mae:0.07201\n",
      "[269]\tTest-mae:0.07199\n",
      "[270]\tTest-mae:0.07197\n",
      "[271]\tTest-mae:0.07193\n",
      "[272]\tTest-mae:0.07189\n",
      "[273]\tTest-mae:0.07186\n",
      "[274]\tTest-mae:0.07184\n",
      "[275]\tTest-mae:0.07180\n",
      "[276]\tTest-mae:0.07179\n",
      "[277]\tTest-mae:0.07178\n",
      "[278]\tTest-mae:0.07177\n",
      "[279]\tTest-mae:0.07177\n",
      "[280]\tTest-mae:0.07175\n",
      "[281]\tTest-mae:0.07175\n",
      "[282]\tTest-mae:0.07173\n",
      "[283]\tTest-mae:0.07171\n",
      "[284]\tTest-mae:0.07171\n",
      "[285]\tTest-mae:0.07171\n",
      "[286]\tTest-mae:0.07168\n",
      "[287]\tTest-mae:0.07165\n",
      "[288]\tTest-mae:0.07161\n",
      "[289]\tTest-mae:0.07157\n",
      "[290]\tTest-mae:0.07156\n",
      "[291]\tTest-mae:0.07156\n",
      "[292]\tTest-mae:0.07154\n",
      "[293]\tTest-mae:0.07150\n",
      "[294]\tTest-mae:0.07148\n",
      "[295]\tTest-mae:0.07146\n",
      "[296]\tTest-mae:0.07145\n",
      "[297]\tTest-mae:0.07144\n",
      "[298]\tTest-mae:0.07143\n",
      "[299]\tTest-mae:0.07142\n",
      "[300]\tTest-mae:0.07140\n",
      "[301]\tTest-mae:0.07140\n",
      "[302]\tTest-mae:0.07136\n",
      "[303]\tTest-mae:0.07135\n",
      "[304]\tTest-mae:0.07134\n",
      "[305]\tTest-mae:0.07133\n",
      "[306]\tTest-mae:0.07130\n",
      "[307]\tTest-mae:0.07129\n",
      "[308]\tTest-mae:0.07127\n",
      "[309]\tTest-mae:0.07127\n",
      "[310]\tTest-mae:0.07125\n",
      "[311]\tTest-mae:0.07124\n",
      "[312]\tTest-mae:0.07124\n",
      "[313]\tTest-mae:0.07120\n",
      "[314]\tTest-mae:0.07119\n",
      "[315]\tTest-mae:0.07119\n",
      "[316]\tTest-mae:0.07117\n",
      "[317]\tTest-mae:0.07113\n",
      "[318]\tTest-mae:0.07111\n",
      "[319]\tTest-mae:0.07107\n",
      "[320]\tTest-mae:0.07104\n",
      "[321]\tTest-mae:0.07101\n",
      "[322]\tTest-mae:0.07100\n",
      "[323]\tTest-mae:0.07100\n",
      "[324]\tTest-mae:0.07098\n",
      "[325]\tTest-mae:0.07097\n",
      "[326]\tTest-mae:0.07097\n",
      "[327]\tTest-mae:0.07095\n",
      "[328]\tTest-mae:0.07094\n",
      "[329]\tTest-mae:0.07092\n",
      "[330]\tTest-mae:0.07091\n",
      "[331]\tTest-mae:0.07089\n",
      "[332]\tTest-mae:0.07088\n",
      "[333]\tTest-mae:0.07085\n",
      "[334]\tTest-mae:0.07083\n",
      "[335]\tTest-mae:0.07081\n",
      "[336]\tTest-mae:0.07078\n",
      "[337]\tTest-mae:0.07077\n",
      "[338]\tTest-mae:0.07072\n",
      "[339]\tTest-mae:0.07071\n",
      "[340]\tTest-mae:0.07071\n",
      "[341]\tTest-mae:0.07071\n",
      "[342]\tTest-mae:0.07071\n",
      "[343]\tTest-mae:0.07068\n",
      "[344]\tTest-mae:0.07066\n",
      "[345]\tTest-mae:0.07065\n",
      "[346]\tTest-mae:0.07064\n",
      "[347]\tTest-mae:0.07059\n",
      "[348]\tTest-mae:0.07059\n",
      "[349]\tTest-mae:0.07057\n",
      "[350]\tTest-mae:0.07056\n",
      "[351]\tTest-mae:0.07056\n",
      "[352]\tTest-mae:0.07054\n",
      "[353]\tTest-mae:0.07054\n",
      "[354]\tTest-mae:0.07051\n",
      "[355]\tTest-mae:0.07050\n",
      "[356]\tTest-mae:0.07047\n",
      "[357]\tTest-mae:0.07046\n",
      "[358]\tTest-mae:0.07046\n",
      "[359]\tTest-mae:0.07045\n",
      "[360]\tTest-mae:0.07043\n",
      "[361]\tTest-mae:0.07040\n",
      "[362]\tTest-mae:0.07040\n",
      "[363]\tTest-mae:0.07040\n",
      "[364]\tTest-mae:0.07040\n",
      "[365]\tTest-mae:0.07038\n",
      "[366]\tTest-mae:0.07036\n",
      "[367]\tTest-mae:0.07035\n",
      "[368]\tTest-mae:0.07034\n",
      "[369]\tTest-mae:0.07033\n",
      "[370]\tTest-mae:0.07031\n",
      "[371]\tTest-mae:0.07030\n",
      "[372]\tTest-mae:0.07030\n",
      "[373]\tTest-mae:0.07029\n",
      "[374]\tTest-mae:0.07028\n",
      "[375]\tTest-mae:0.07027\n",
      "[376]\tTest-mae:0.07026\n",
      "[377]\tTest-mae:0.07025\n",
      "[378]\tTest-mae:0.07025\n",
      "[379]\tTest-mae:0.07024\n",
      "[380]\tTest-mae:0.07023\n",
      "[381]\tTest-mae:0.07022\n",
      "[382]\tTest-mae:0.07022\n",
      "[383]\tTest-mae:0.07022\n",
      "[384]\tTest-mae:0.07022\n",
      "[385]\tTest-mae:0.07020\n",
      "[386]\tTest-mae:0.07020\n",
      "[387]\tTest-mae:0.07019\n",
      "[388]\tTest-mae:0.07018\n",
      "[389]\tTest-mae:0.07016\n",
      "[390]\tTest-mae:0.07015\n",
      "[391]\tTest-mae:0.07015\n",
      "[392]\tTest-mae:0.07014\n",
      "[393]\tTest-mae:0.07013\n",
      "[394]\tTest-mae:0.07011\n",
      "[395]\tTest-mae:0.07010\n",
      "[396]\tTest-mae:0.07009\n",
      "[397]\tTest-mae:0.07008\n",
      "[398]\tTest-mae:0.07004\n",
      "[399]\tTest-mae:0.07003\n",
      "[400]\tTest-mae:0.07001\n",
      "[401]\tTest-mae:0.07001\n",
      "[402]\tTest-mae:0.07000\n",
      "[403]\tTest-mae:0.06997\n",
      "[404]\tTest-mae:0.06995\n",
      "[405]\tTest-mae:0.06994\n",
      "[406]\tTest-mae:0.06992\n",
      "[407]\tTest-mae:0.06991\n",
      "[408]\tTest-mae:0.06991\n",
      "[409]\tTest-mae:0.06987\n",
      "[410]\tTest-mae:0.06987\n",
      "[411]\tTest-mae:0.06983\n",
      "[412]\tTest-mae:0.06982\n",
      "[413]\tTest-mae:0.06982\n",
      "[414]\tTest-mae:0.06981\n",
      "[415]\tTest-mae:0.06978\n",
      "[416]\tTest-mae:0.06978\n",
      "[417]\tTest-mae:0.06977\n",
      "[418]\tTest-mae:0.06976\n",
      "[419]\tTest-mae:0.06975\n",
      "[420]\tTest-mae:0.06974\n",
      "[421]\tTest-mae:0.06974\n",
      "[422]\tTest-mae:0.06974\n",
      "[423]\tTest-mae:0.06973\n",
      "[424]\tTest-mae:0.06970\n",
      "[425]\tTest-mae:0.06970\n",
      "[426]\tTest-mae:0.06970\n",
      "[427]\tTest-mae:0.06969\n",
      "[428]\tTest-mae:0.06968\n",
      "[429]\tTest-mae:0.06966\n",
      "[430]\tTest-mae:0.06964\n",
      "[431]\tTest-mae:0.06962\n",
      "[432]\tTest-mae:0.06961\n",
      "[433]\tTest-mae:0.06960\n",
      "[434]\tTest-mae:0.06960\n",
      "[435]\tTest-mae:0.06959\n",
      "[436]\tTest-mae:0.06958\n",
      "[437]\tTest-mae:0.06957\n",
      "[438]\tTest-mae:0.06955\n",
      "[439]\tTest-mae:0.06954\n",
      "[440]\tTest-mae:0.06953\n",
      "[441]\tTest-mae:0.06953\n",
      "[442]\tTest-mae:0.06953\n",
      "[443]\tTest-mae:0.06951\n",
      "[444]\tTest-mae:0.06951\n",
      "[445]\tTest-mae:0.06950\n",
      "[446]\tTest-mae:0.06948\n",
      "[447]\tTest-mae:0.06947\n",
      "[448]\tTest-mae:0.06945\n",
      "[449]\tTest-mae:0.06944\n",
      "[450]\tTest-mae:0.06943\n",
      "[451]\tTest-mae:0.06942\n",
      "[452]\tTest-mae:0.06941\n",
      "[453]\tTest-mae:0.06940\n",
      "[454]\tTest-mae:0.06940\n",
      "[455]\tTest-mae:0.06939\n",
      "[456]\tTest-mae:0.06936\n",
      "[457]\tTest-mae:0.06934\n",
      "[458]\tTest-mae:0.06933\n",
      "[459]\tTest-mae:0.06934\n",
      "[460]\tTest-mae:0.06932\n",
      "[461]\tTest-mae:0.06932\n",
      "[462]\tTest-mae:0.06931\n",
      "[463]\tTest-mae:0.06931\n",
      "[464]\tTest-mae:0.06930\n",
      "[465]\tTest-mae:0.06929\n",
      "[466]\tTest-mae:0.06928\n",
      "[467]\tTest-mae:0.06928\n",
      "[468]\tTest-mae:0.06928\n",
      "[469]\tTest-mae:0.06928\n",
      "[470]\tTest-mae:0.06926\n",
      "[471]\tTest-mae:0.06926\n",
      "[472]\tTest-mae:0.06926\n",
      "[473]\tTest-mae:0.06926\n",
      "[474]\tTest-mae:0.06925\n",
      "[475]\tTest-mae:0.06924\n",
      "[476]\tTest-mae:0.06924\n",
      "[477]\tTest-mae:0.06924\n",
      "[478]\tTest-mae:0.06923\n",
      "[479]\tTest-mae:0.06922\n",
      "[480]\tTest-mae:0.06920\n",
      "[481]\tTest-mae:0.06919\n",
      "[482]\tTest-mae:0.06919\n",
      "[483]\tTest-mae:0.06918\n",
      "[484]\tTest-mae:0.06916\n",
      "[485]\tTest-mae:0.06916\n",
      "[486]\tTest-mae:0.06916\n",
      "[487]\tTest-mae:0.06915\n",
      "[488]\tTest-mae:0.06914\n",
      "[489]\tTest-mae:0.06911\n",
      "[490]\tTest-mae:0.06911\n",
      "[491]\tTest-mae:0.06910\n",
      "[492]\tTest-mae:0.06908\n",
      "[493]\tTest-mae:0.06908\n",
      "[494]\tTest-mae:0.06908\n",
      "[495]\tTest-mae:0.06908\n",
      "[496]\tTest-mae:0.06907\n",
      "[497]\tTest-mae:0.06907\n",
      "[498]\tTest-mae:0.06906\n",
      "[499]\tTest-mae:0.06906\n",
      "[500]\tTest-mae:0.06904\n",
      "[501]\tTest-mae:0.06904\n",
      "[502]\tTest-mae:0.06903\n",
      "[503]\tTest-mae:0.06902\n",
      "[504]\tTest-mae:0.06901\n",
      "[505]\tTest-mae:0.06900\n",
      "[506]\tTest-mae:0.06897\n",
      "[507]\tTest-mae:0.06897\n",
      "[508]\tTest-mae:0.06897\n",
      "[509]\tTest-mae:0.06895\n",
      "[510]\tTest-mae:0.06895\n",
      "[511]\tTest-mae:0.06895\n",
      "[512]\tTest-mae:0.06894\n",
      "[513]\tTest-mae:0.06893\n",
      "[514]\tTest-mae:0.06892\n",
      "[515]\tTest-mae:0.06892\n",
      "[516]\tTest-mae:0.06891\n",
      "[517]\tTest-mae:0.06890\n",
      "[518]\tTest-mae:0.06890\n",
      "[519]\tTest-mae:0.06889\n",
      "[520]\tTest-mae:0.06889\n",
      "[521]\tTest-mae:0.06888\n",
      "[522]\tTest-mae:0.06886\n",
      "[523]\tTest-mae:0.06885\n",
      "[524]\tTest-mae:0.06884\n",
      "[525]\tTest-mae:0.06884\n",
      "[526]\tTest-mae:0.06883\n",
      "[527]\tTest-mae:0.06883\n",
      "[528]\tTest-mae:0.06881\n",
      "[529]\tTest-mae:0.06880\n",
      "[530]\tTest-mae:0.06879\n",
      "[531]\tTest-mae:0.06878\n",
      "[532]\tTest-mae:0.06878\n",
      "[533]\tTest-mae:0.06877\n",
      "[534]\tTest-mae:0.06877\n",
      "[535]\tTest-mae:0.06877\n",
      "[536]\tTest-mae:0.06876\n",
      "[537]\tTest-mae:0.06875\n",
      "[538]\tTest-mae:0.06874\n",
      "[539]\tTest-mae:0.06872\n",
      "[540]\tTest-mae:0.06871\n",
      "[541]\tTest-mae:0.06871\n",
      "[542]\tTest-mae:0.06871\n",
      "[543]\tTest-mae:0.06870\n",
      "[544]\tTest-mae:0.06869\n",
      "[545]\tTest-mae:0.06867\n",
      "[546]\tTest-mae:0.06867\n",
      "[547]\tTest-mae:0.06866\n",
      "[548]\tTest-mae:0.06865\n",
      "[549]\tTest-mae:0.06865\n",
      "[550]\tTest-mae:0.06864\n",
      "[551]\tTest-mae:0.06864\n",
      "[552]\tTest-mae:0.06863\n",
      "[553]\tTest-mae:0.06861\n",
      "[554]\tTest-mae:0.06861\n",
      "[555]\tTest-mae:0.06858\n",
      "[556]\tTest-mae:0.06858\n",
      "[557]\tTest-mae:0.06857\n",
      "[558]\tTest-mae:0.06857\n",
      "[559]\tTest-mae:0.06856\n",
      "[560]\tTest-mae:0.06854\n",
      "[561]\tTest-mae:0.06853\n",
      "[562]\tTest-mae:0.06853\n",
      "[563]\tTest-mae:0.06851\n",
      "[564]\tTest-mae:0.06850\n",
      "[565]\tTest-mae:0.06849\n",
      "[566]\tTest-mae:0.06848\n",
      "[567]\tTest-mae:0.06848\n",
      "[568]\tTest-mae:0.06848\n",
      "[569]\tTest-mae:0.06847\n",
      "[570]\tTest-mae:0.06847\n",
      "[571]\tTest-mae:0.06847\n",
      "[572]\tTest-mae:0.06846\n",
      "[573]\tTest-mae:0.06845\n",
      "[574]\tTest-mae:0.06845\n",
      "[575]\tTest-mae:0.06845\n",
      "[576]\tTest-mae:0.06845\n",
      "[577]\tTest-mae:0.06844\n",
      "[578]\tTest-mae:0.06842\n",
      "[579]\tTest-mae:0.06842\n",
      "[580]\tTest-mae:0.06840\n",
      "[581]\tTest-mae:0.06840\n",
      "[582]\tTest-mae:0.06840\n",
      "[583]\tTest-mae:0.06839\n",
      "[584]\tTest-mae:0.06839\n",
      "[585]\tTest-mae:0.06840\n",
      "[586]\tTest-mae:0.06839\n",
      "[587]\tTest-mae:0.06839\n",
      "[588]\tTest-mae:0.06838\n",
      "[589]\tTest-mae:0.06838\n",
      "[590]\tTest-mae:0.06837\n",
      "[591]\tTest-mae:0.06836\n",
      "[592]\tTest-mae:0.06835\n",
      "[593]\tTest-mae:0.06833\n",
      "[594]\tTest-mae:0.06833\n",
      "[595]\tTest-mae:0.06832\n",
      "[596]\tTest-mae:0.06832\n",
      "[597]\tTest-mae:0.06832\n",
      "[598]\tTest-mae:0.06831\n",
      "[599]\tTest-mae:0.06831\n",
      "[600]\tTest-mae:0.06830\n",
      "[601]\tTest-mae:0.06828\n",
      "[602]\tTest-mae:0.06827\n",
      "[603]\tTest-mae:0.06826\n",
      "[604]\tTest-mae:0.06826\n",
      "[605]\tTest-mae:0.06825\n",
      "[606]\tTest-mae:0.06824\n",
      "[607]\tTest-mae:0.06824\n",
      "[608]\tTest-mae:0.06824\n",
      "[609]\tTest-mae:0.06822\n",
      "[610]\tTest-mae:0.06821\n",
      "[611]\tTest-mae:0.06821\n",
      "[612]\tTest-mae:0.06820\n",
      "[613]\tTest-mae:0.06820\n",
      "[614]\tTest-mae:0.06820\n",
      "[615]\tTest-mae:0.06819\n",
      "[616]\tTest-mae:0.06818\n",
      "[617]\tTest-mae:0.06818\n",
      "[618]\tTest-mae:0.06817\n",
      "[619]\tTest-mae:0.06816\n",
      "[620]\tTest-mae:0.06815\n",
      "[621]\tTest-mae:0.06815\n",
      "[622]\tTest-mae:0.06814\n",
      "[623]\tTest-mae:0.06814\n",
      "[624]\tTest-mae:0.06814\n",
      "[625]\tTest-mae:0.06813\n",
      "[626]\tTest-mae:0.06812\n",
      "[627]\tTest-mae:0.06810\n",
      "[628]\tTest-mae:0.06810\n",
      "[629]\tTest-mae:0.06810\n",
      "[630]\tTest-mae:0.06809\n",
      "[631]\tTest-mae:0.06809\n",
      "[632]\tTest-mae:0.06808\n",
      "[633]\tTest-mae:0.06808\n",
      "[634]\tTest-mae:0.06808\n",
      "[635]\tTest-mae:0.06807\n",
      "[636]\tTest-mae:0.06806\n",
      "[637]\tTest-mae:0.06805\n",
      "[638]\tTest-mae:0.06804\n",
      "[639]\tTest-mae:0.06804\n",
      "[640]\tTest-mae:0.06804\n",
      "[641]\tTest-mae:0.06803\n",
      "[642]\tTest-mae:0.06802\n",
      "[643]\tTest-mae:0.06802\n",
      "[644]\tTest-mae:0.06801\n",
      "[645]\tTest-mae:0.06801\n",
      "[646]\tTest-mae:0.06800\n",
      "[647]\tTest-mae:0.06799\n",
      "[648]\tTest-mae:0.06798\n",
      "[649]\tTest-mae:0.06797\n",
      "[650]\tTest-mae:0.06797\n",
      "[651]\tTest-mae:0.06797\n",
      "[652]\tTest-mae:0.06796\n",
      "[653]\tTest-mae:0.06796\n",
      "[654]\tTest-mae:0.06796\n",
      "[655]\tTest-mae:0.06796\n",
      "[656]\tTest-mae:0.06796\n",
      "[657]\tTest-mae:0.06796\n",
      "[658]\tTest-mae:0.06794\n",
      "[659]\tTest-mae:0.06794\n",
      "[660]\tTest-mae:0.06793\n",
      "[661]\tTest-mae:0.06792\n",
      "[662]\tTest-mae:0.06792\n",
      "[663]\tTest-mae:0.06792\n",
      "[664]\tTest-mae:0.06791\n",
      "[665]\tTest-mae:0.06790\n",
      "[666]\tTest-mae:0.06790\n",
      "[667]\tTest-mae:0.06789\n",
      "[668]\tTest-mae:0.06788\n",
      "[669]\tTest-mae:0.06787\n",
      "[670]\tTest-mae:0.06787\n",
      "[671]\tTest-mae:0.06787\n",
      "[672]\tTest-mae:0.06786\n",
      "[673]\tTest-mae:0.06784\n",
      "[674]\tTest-mae:0.06784\n",
      "[675]\tTest-mae:0.06784\n",
      "[676]\tTest-mae:0.06784\n",
      "[677]\tTest-mae:0.06784\n",
      "[678]\tTest-mae:0.06782\n",
      "[679]\tTest-mae:0.06782\n",
      "[680]\tTest-mae:0.06781\n",
      "[681]\tTest-mae:0.06781\n",
      "[682]\tTest-mae:0.06781\n",
      "[683]\tTest-mae:0.06781\n",
      "[684]\tTest-mae:0.06781\n",
      "[685]\tTest-mae:0.06779\n",
      "[686]\tTest-mae:0.06779\n",
      "[687]\tTest-mae:0.06779\n",
      "[688]\tTest-mae:0.06779\n",
      "[689]\tTest-mae:0.06779\n",
      "[690]\tTest-mae:0.06779\n",
      "[691]\tTest-mae:0.06778\n",
      "[692]\tTest-mae:0.06778\n",
      "[693]\tTest-mae:0.06777\n",
      "[694]\tTest-mae:0.06777\n",
      "[695]\tTest-mae:0.06776\n",
      "[696]\tTest-mae:0.06775\n",
      "[697]\tTest-mae:0.06774\n",
      "[698]\tTest-mae:0.06774\n",
      "[699]\tTest-mae:0.06773\n",
      "[700]\tTest-mae:0.06773\n",
      "[701]\tTest-mae:0.06773\n",
      "[702]\tTest-mae:0.06772\n",
      "[703]\tTest-mae:0.06772\n",
      "[704]\tTest-mae:0.06771\n",
      "[705]\tTest-mae:0.06771\n",
      "[706]\tTest-mae:0.06770\n",
      "[707]\tTest-mae:0.06769\n",
      "[708]\tTest-mae:0.06769\n",
      "[709]\tTest-mae:0.06768\n",
      "[710]\tTest-mae:0.06767\n",
      "[711]\tTest-mae:0.06767\n",
      "[712]\tTest-mae:0.06767\n",
      "[713]\tTest-mae:0.06767\n",
      "[714]\tTest-mae:0.06766\n",
      "[715]\tTest-mae:0.06766\n",
      "[716]\tTest-mae:0.06766\n",
      "[717]\tTest-mae:0.06765\n",
      "[718]\tTest-mae:0.06765\n",
      "[719]\tTest-mae:0.06765\n",
      "[720]\tTest-mae:0.06764\n",
      "[721]\tTest-mae:0.06763\n",
      "[722]\tTest-mae:0.06763\n",
      "[723]\tTest-mae:0.06763\n",
      "[724]\tTest-mae:0.06762\n",
      "[725]\tTest-mae:0.06763\n",
      "[726]\tTest-mae:0.06762\n",
      "[727]\tTest-mae:0.06762\n",
      "[728]\tTest-mae:0.06761\n",
      "[729]\tTest-mae:0.06761\n",
      "[730]\tTest-mae:0.06760\n",
      "[731]\tTest-mae:0.06760\n",
      "[732]\tTest-mae:0.06760\n",
      "[733]\tTest-mae:0.06759\n",
      "[734]\tTest-mae:0.06758\n",
      "[735]\tTest-mae:0.06758\n",
      "[736]\tTest-mae:0.06758\n",
      "[737]\tTest-mae:0.06758\n",
      "[738]\tTest-mae:0.06757\n",
      "[739]\tTest-mae:0.06757\n",
      "[740]\tTest-mae:0.06756\n",
      "[741]\tTest-mae:0.06755\n",
      "[742]\tTest-mae:0.06754\n",
      "[743]\tTest-mae:0.06754\n",
      "[744]\tTest-mae:0.06754\n",
      "[745]\tTest-mae:0.06753\n",
      "[746]\tTest-mae:0.06753\n",
      "[747]\tTest-mae:0.06752\n",
      "[748]\tTest-mae:0.06752\n",
      "[749]\tTest-mae:0.06752\n",
      "[750]\tTest-mae:0.06752\n",
      "[751]\tTest-mae:0.06751\n",
      "[752]\tTest-mae:0.06751\n",
      "[753]\tTest-mae:0.06751\n",
      "[754]\tTest-mae:0.06750\n",
      "[755]\tTest-mae:0.06749\n",
      "[756]\tTest-mae:0.06750\n",
      "[757]\tTest-mae:0.06749\n",
      "[758]\tTest-mae:0.06749\n",
      "[759]\tTest-mae:0.06748\n",
      "[760]\tTest-mae:0.06748\n",
      "[761]\tTest-mae:0.06747\n",
      "[762]\tTest-mae:0.06746\n",
      "[763]\tTest-mae:0.06746\n",
      "[764]\tTest-mae:0.06746\n",
      "[765]\tTest-mae:0.06746\n",
      "[766]\tTest-mae:0.06745\n",
      "[767]\tTest-mae:0.06745\n",
      "[768]\tTest-mae:0.06744\n",
      "[769]\tTest-mae:0.06744\n",
      "[770]\tTest-mae:0.06744\n",
      "[771]\tTest-mae:0.06743\n",
      "[772]\tTest-mae:0.06742\n",
      "[773]\tTest-mae:0.06742\n",
      "[774]\tTest-mae:0.06741\n",
      "[775]\tTest-mae:0.06741\n",
      "[776]\tTest-mae:0.06739\n",
      "[777]\tTest-mae:0.06739\n",
      "[778]\tTest-mae:0.06739\n",
      "[779]\tTest-mae:0.06739\n",
      "[780]\tTest-mae:0.06738\n",
      "[781]\tTest-mae:0.06737\n",
      "[782]\tTest-mae:0.06737\n",
      "[783]\tTest-mae:0.06735\n",
      "[784]\tTest-mae:0.06735\n",
      "[785]\tTest-mae:0.06735\n",
      "[786]\tTest-mae:0.06735\n",
      "[787]\tTest-mae:0.06733\n",
      "[788]\tTest-mae:0.06733\n",
      "[789]\tTest-mae:0.06733\n",
      "[790]\tTest-mae:0.06732\n",
      "[791]\tTest-mae:0.06732\n",
      "[792]\tTest-mae:0.06732\n",
      "[793]\tTest-mae:0.06731\n",
      "[794]\tTest-mae:0.06731\n",
      "[795]\tTest-mae:0.06730\n",
      "[796]\tTest-mae:0.06730\n",
      "[797]\tTest-mae:0.06730\n",
      "[798]\tTest-mae:0.06730\n",
      "[799]\tTest-mae:0.06730\n",
      "[800]\tTest-mae:0.06729\n",
      "[801]\tTest-mae:0.06728\n",
      "[802]\tTest-mae:0.06728\n",
      "[803]\tTest-mae:0.06728\n",
      "[804]\tTest-mae:0.06727\n",
      "[805]\tTest-mae:0.06726\n",
      "[806]\tTest-mae:0.06726\n",
      "[807]\tTest-mae:0.06726\n",
      "[808]\tTest-mae:0.06725\n",
      "[809]\tTest-mae:0.06724\n",
      "[810]\tTest-mae:0.06724\n",
      "[811]\tTest-mae:0.06724\n",
      "[812]\tTest-mae:0.06723\n",
      "[813]\tTest-mae:0.06723\n",
      "[814]\tTest-mae:0.06722\n",
      "[815]\tTest-mae:0.06722\n",
      "[816]\tTest-mae:0.06721\n",
      "[817]\tTest-mae:0.06721\n",
      "[818]\tTest-mae:0.06721\n",
      "[819]\tTest-mae:0.06721\n",
      "[820]\tTest-mae:0.06721\n",
      "[821]\tTest-mae:0.06720\n",
      "[822]\tTest-mae:0.06720\n",
      "[823]\tTest-mae:0.06720\n",
      "[824]\tTest-mae:0.06719\n",
      "[825]\tTest-mae:0.06719\n",
      "[826]\tTest-mae:0.06718\n",
      "[827]\tTest-mae:0.06718\n",
      "[828]\tTest-mae:0.06717\n",
      "[829]\tTest-mae:0.06717\n",
      "[830]\tTest-mae:0.06717\n",
      "[831]\tTest-mae:0.06716\n",
      "[832]\tTest-mae:0.06716\n",
      "[833]\tTest-mae:0.06716\n",
      "[834]\tTest-mae:0.06716\n",
      "[835]\tTest-mae:0.06714\n",
      "[836]\tTest-mae:0.06714\n",
      "[837]\tTest-mae:0.06713\n",
      "[838]\tTest-mae:0.06712\n",
      "[839]\tTest-mae:0.06711\n",
      "[840]\tTest-mae:0.06711\n",
      "[841]\tTest-mae:0.06710\n",
      "[842]\tTest-mae:0.06711\n",
      "[843]\tTest-mae:0.06710\n",
      "[844]\tTest-mae:0.06710\n",
      "[845]\tTest-mae:0.06710\n",
      "[846]\tTest-mae:0.06709\n",
      "[847]\tTest-mae:0.06709\n",
      "[848]\tTest-mae:0.06709\n",
      "[849]\tTest-mae:0.06708\n",
      "[850]\tTest-mae:0.06707\n",
      "[851]\tTest-mae:0.06707\n",
      "[852]\tTest-mae:0.06707\n",
      "[853]\tTest-mae:0.06707\n",
      "[854]\tTest-mae:0.06707\n",
      "[855]\tTest-mae:0.06706\n",
      "[856]\tTest-mae:0.06705\n",
      "[857]\tTest-mae:0.06705\n",
      "[858]\tTest-mae:0.06705\n",
      "[859]\tTest-mae:0.06704\n",
      "[860]\tTest-mae:0.06704\n",
      "[861]\tTest-mae:0.06704\n",
      "[862]\tTest-mae:0.06703\n",
      "[863]\tTest-mae:0.06703\n",
      "[864]\tTest-mae:0.06703\n",
      "[865]\tTest-mae:0.06703\n",
      "[866]\tTest-mae:0.06703\n",
      "[867]\tTest-mae:0.06703\n",
      "[868]\tTest-mae:0.06702\n",
      "[869]\tTest-mae:0.06702\n",
      "[870]\tTest-mae:0.06701\n",
      "[871]\tTest-mae:0.06701\n",
      "[872]\tTest-mae:0.06701\n",
      "[873]\tTest-mae:0.06700\n",
      "[874]\tTest-mae:0.06700\n",
      "[875]\tTest-mae:0.06700\n",
      "[876]\tTest-mae:0.06699\n",
      "[877]\tTest-mae:0.06699\n",
      "[878]\tTest-mae:0.06699\n",
      "[879]\tTest-mae:0.06698\n",
      "[880]\tTest-mae:0.06698\n",
      "[881]\tTest-mae:0.06697\n",
      "[882]\tTest-mae:0.06697\n",
      "[883]\tTest-mae:0.06697\n",
      "[884]\tTest-mae:0.06696\n",
      "[885]\tTest-mae:0.06696\n",
      "[886]\tTest-mae:0.06695\n",
      "[887]\tTest-mae:0.06695\n",
      "[888]\tTest-mae:0.06695\n",
      "[889]\tTest-mae:0.06695\n",
      "[890]\tTest-mae:0.06694\n",
      "[891]\tTest-mae:0.06694\n",
      "[892]\tTest-mae:0.06693\n",
      "[893]\tTest-mae:0.06693\n",
      "[894]\tTest-mae:0.06693\n",
      "[895]\tTest-mae:0.06693\n",
      "[896]\tTest-mae:0.06693\n",
      "[897]\tTest-mae:0.06692\n",
      "[898]\tTest-mae:0.06692\n",
      "[899]\tTest-mae:0.06692\n",
      "[900]\tTest-mae:0.06692\n",
      "[901]\tTest-mae:0.06692\n",
      "[902]\tTest-mae:0.06692\n",
      "[903]\tTest-mae:0.06691\n",
      "[904]\tTest-mae:0.06691\n",
      "[905]\tTest-mae:0.06691\n",
      "[906]\tTest-mae:0.06691\n",
      "[907]\tTest-mae:0.06691\n",
      "[908]\tTest-mae:0.06690\n",
      "[909]\tTest-mae:0.06689\n",
      "[910]\tTest-mae:0.06689\n",
      "[911]\tTest-mae:0.06688\n",
      "[912]\tTest-mae:0.06688\n",
      "[913]\tTest-mae:0.06688\n",
      "[914]\tTest-mae:0.06688\n",
      "[915]\tTest-mae:0.06687\n",
      "[916]\tTest-mae:0.06687\n",
      "[917]\tTest-mae:0.06687\n",
      "[918]\tTest-mae:0.06686\n",
      "[919]\tTest-mae:0.06686\n",
      "[920]\tTest-mae:0.06686\n",
      "[921]\tTest-mae:0.06686\n",
      "[922]\tTest-mae:0.06686\n",
      "[923]\tTest-mae:0.06685\n",
      "[924]\tTest-mae:0.06685\n",
      "[925]\tTest-mae:0.06685\n",
      "[926]\tTest-mae:0.06685\n",
      "[927]\tTest-mae:0.06685\n",
      "[928]\tTest-mae:0.06684\n",
      "[929]\tTest-mae:0.06684\n",
      "[930]\tTest-mae:0.06684\n",
      "[931]\tTest-mae:0.06682\n",
      "[932]\tTest-mae:0.06681\n",
      "[933]\tTest-mae:0.06681\n",
      "[934]\tTest-mae:0.06681\n",
      "[935]\tTest-mae:0.06681\n",
      "[936]\tTest-mae:0.06681\n",
      "[937]\tTest-mae:0.06681\n",
      "[938]\tTest-mae:0.06680\n",
      "[939]\tTest-mae:0.06681\n",
      "[940]\tTest-mae:0.06680\n",
      "[941]\tTest-mae:0.06680\n",
      "[942]\tTest-mae:0.06680\n",
      "[943]\tTest-mae:0.06680\n",
      "[944]\tTest-mae:0.06680\n",
      "[945]\tTest-mae:0.06680\n",
      "[946]\tTest-mae:0.06680\n",
      "[947]\tTest-mae:0.06679\n",
      "[948]\tTest-mae:0.06679\n",
      "[949]\tTest-mae:0.06679\n",
      "[950]\tTest-mae:0.06679\n",
      "[951]\tTest-mae:0.06678\n",
      "[952]\tTest-mae:0.06678\n",
      "[953]\tTest-mae:0.06678\n",
      "[954]\tTest-mae:0.06677\n",
      "[955]\tTest-mae:0.06677\n",
      "[956]\tTest-mae:0.06677\n",
      "[957]\tTest-mae:0.06676\n",
      "[958]\tTest-mae:0.06676\n",
      "[959]\tTest-mae:0.06676\n",
      "[960]\tTest-mae:0.06676\n",
      "[961]\tTest-mae:0.06675\n",
      "[962]\tTest-mae:0.06675\n",
      "[963]\tTest-mae:0.06674\n",
      "[964]\tTest-mae:0.06674\n",
      "[965]\tTest-mae:0.06674\n",
      "[966]\tTest-mae:0.06674\n",
      "[967]\tTest-mae:0.06674\n",
      "[968]\tTest-mae:0.06673\n",
      "[969]\tTest-mae:0.06673\n",
      "[970]\tTest-mae:0.06673\n",
      "[971]\tTest-mae:0.06673\n",
      "[972]\tTest-mae:0.06673\n",
      "[973]\tTest-mae:0.06673\n",
      "[974]\tTest-mae:0.06672\n",
      "[975]\tTest-mae:0.06672\n",
      "[976]\tTest-mae:0.06672\n",
      "[977]\tTest-mae:0.06671\n",
      "[978]\tTest-mae:0.06671\n",
      "[979]\tTest-mae:0.06670\n",
      "[980]\tTest-mae:0.06670\n",
      "[981]\tTest-mae:0.06670\n",
      "[982]\tTest-mae:0.06670\n",
      "[983]\tTest-mae:0.06670\n",
      "[984]\tTest-mae:0.06669\n",
      "[985]\tTest-mae:0.06669\n",
      "[986]\tTest-mae:0.06669\n",
      "[987]\tTest-mae:0.06669\n",
      "[988]\tTest-mae:0.06668\n",
      "[989]\tTest-mae:0.06668\n",
      "[990]\tTest-mae:0.06668\n",
      "[991]\tTest-mae:0.06668\n",
      "[992]\tTest-mae:0.06667\n",
      "[993]\tTest-mae:0.06668\n",
      "[994]\tTest-mae:0.06667\n",
      "[995]\tTest-mae:0.06667\n",
      "[996]\tTest-mae:0.06667\n",
      "[997]\tTest-mae:0.06667\n",
      "[998]\tTest-mae:0.06666\n",
      "[999]\tTest-mae:0.06666\n",
      "[1000]\tTest-mae:0.06666\n",
      "[1001]\tTest-mae:0.06665\n",
      "[1002]\tTest-mae:0.06665\n",
      "[1003]\tTest-mae:0.06665\n",
      "[1004]\tTest-mae:0.06665\n",
      "[1005]\tTest-mae:0.06665\n",
      "[1006]\tTest-mae:0.06664\n",
      "[1007]\tTest-mae:0.06664\n",
      "[1008]\tTest-mae:0.06664\n",
      "Best MAE: 0.06790 in 1000 rounds\n",
      "MAE for best modeL:  0.06663846322330921\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import xgboost as xgb'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "I am merging .. wp1\n",
      "my X length is.. 13488\n",
      "my y length is.. 13488\n",
      "I am merging .. wp2\n",
      "my X length is.. 26976\n",
      "my y length is.. 26976\n",
      "my_X_forecast length is.. 14880\n",
      "my_test length is.. 14880\n",
      "I am merging .. wp3\n",
      "my X length is.. 40464\n",
      "my y length is.. 40464\n",
      "my_X_forecast length is.. 22320\n",
      "my_test length is.. 22320\n",
      "I am merging .. wp4\n",
      "my X length is.. 53952\n",
      "my y length is.. 53952\n",
      "my_X_forecast length is.. 29760\n",
      "my_test length is.. 29760\n",
      "I am merging .. wp5\n",
      "my X length is.. 67440\n",
      "my y length is.. 67440\n",
      "my_X_forecast length is.. 37200\n",
      "my_test length is.. 37200\n",
      "I am merging .. wp6\n",
      "my X length is.. 80928\n",
      "my y length is.. 80928\n",
      "my_X_forecast length is.. 44640\n",
      "my_test length is.. 44640\n",
      "Baseline MAE is 0.23\n",
      "[03:11:24] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tTest-mae:0.31599\n",
      "Will train until Test-mae hasn't improved in 1000 rounds.\n",
      "[1]\tTest-mae:0.30284\n",
      "[2]\tTest-mae:0.29045\n",
      "[3]\tTest-mae:0.27879\n",
      "[4]\tTest-mae:0.26775\n",
      "[5]\tTest-mae:0.25718\n",
      "[6]\tTest-mae:0.24728\n",
      "[7]\tTest-mae:0.23793\n",
      "[8]\tTest-mae:0.22914\n",
      "[9]\tTest-mae:0.22073\n",
      "[10]\tTest-mae:0.21281\n",
      "[11]\tTest-mae:0.20535\n",
      "[12]\tTest-mae:0.19833\n",
      "[13]\tTest-mae:0.19171\n",
      "[14]\tTest-mae:0.18547\n",
      "[15]\tTest-mae:0.17954\n",
      "[16]\tTest-mae:0.17403\n",
      "[17]\tTest-mae:0.16873\n",
      "[18]\tTest-mae:0.16378\n",
      "[19]\tTest-mae:0.15907\n",
      "[20]\tTest-mae:0.15470\n",
      "[21]\tTest-mae:0.15054\n",
      "[22]\tTest-mae:0.14661\n",
      "[23]\tTest-mae:0.14295\n",
      "[24]\tTest-mae:0.13949\n",
      "[25]\tTest-mae:0.13623\n",
      "[26]\tTest-mae:0.13325\n",
      "[27]\tTest-mae:0.13036\n",
      "[28]\tTest-mae:0.12762\n",
      "[29]\tTest-mae:0.12504\n",
      "[30]\tTest-mae:0.12266\n",
      "[31]\tTest-mae:0.12037\n",
      "[32]\tTest-mae:0.11817\n",
      "[33]\tTest-mae:0.11610\n",
      "[34]\tTest-mae:0.11420\n",
      "[35]\tTest-mae:0.11241\n",
      "[36]\tTest-mae:0.11065\n",
      "[37]\tTest-mae:0.10900\n",
      "[38]\tTest-mae:0.10757\n",
      "[39]\tTest-mae:0.10618\n",
      "[40]\tTest-mae:0.10480\n",
      "[41]\tTest-mae:0.10352\n",
      "[42]\tTest-mae:0.10236\n",
      "[43]\tTest-mae:0.10125\n",
      "[44]\tTest-mae:0.10015\n",
      "[45]\tTest-mae:0.09915\n",
      "[46]\tTest-mae:0.09818\n",
      "[47]\tTest-mae:0.09733\n",
      "[48]\tTest-mae:0.09646\n",
      "[49]\tTest-mae:0.09559\n",
      "[50]\tTest-mae:0.09479\n",
      "[51]\tTest-mae:0.09405\n",
      "[52]\tTest-mae:0.09328\n",
      "[53]\tTest-mae:0.09259\n",
      "[54]\tTest-mae:0.09195\n",
      "[55]\tTest-mae:0.09128\n",
      "[56]\tTest-mae:0.09072\n",
      "[57]\tTest-mae:0.09019\n",
      "[58]\tTest-mae:0.08960\n",
      "[59]\tTest-mae:0.08912\n",
      "[60]\tTest-mae:0.08870\n",
      "[61]\tTest-mae:0.08829\n",
      "[62]\tTest-mae:0.08783\n",
      "[63]\tTest-mae:0.08743\n",
      "[64]\tTest-mae:0.08704\n",
      "[65]\tTest-mae:0.08672\n",
      "[66]\tTest-mae:0.08638\n",
      "[67]\tTest-mae:0.08601\n",
      "[68]\tTest-mae:0.08562\n",
      "[69]\tTest-mae:0.08532\n",
      "[70]\tTest-mae:0.08504\n",
      "[71]\tTest-mae:0.08475\n",
      "[72]\tTest-mae:0.08446\n",
      "[73]\tTest-mae:0.08424\n",
      "[74]\tTest-mae:0.08393\n",
      "[75]\tTest-mae:0.08368\n",
      "[76]\tTest-mae:0.08350\n",
      "[77]\tTest-mae:0.08325\n",
      "[78]\tTest-mae:0.08308\n",
      "[79]\tTest-mae:0.08289\n",
      "[80]\tTest-mae:0.08271\n",
      "[81]\tTest-mae:0.08251\n",
      "[82]\tTest-mae:0.08233\n",
      "[83]\tTest-mae:0.08208\n",
      "[84]\tTest-mae:0.08193\n",
      "[85]\tTest-mae:0.08178\n",
      "[86]\tTest-mae:0.08162\n",
      "[87]\tTest-mae:0.08147\n",
      "[88]\tTest-mae:0.08131\n",
      "[89]\tTest-mae:0.08112\n",
      "[90]\tTest-mae:0.08097\n",
      "[91]\tTest-mae:0.08074\n",
      "[92]\tTest-mae:0.08063\n",
      "[93]\tTest-mae:0.08049\n",
      "[94]\tTest-mae:0.08034\n",
      "[95]\tTest-mae:0.08022\n",
      "[96]\tTest-mae:0.08013\n",
      "[97]\tTest-mae:0.07998\n",
      "[98]\tTest-mae:0.07984\n",
      "[99]\tTest-mae:0.07974\n",
      "[100]\tTest-mae:0.07964\n",
      "[101]\tTest-mae:0.07949\n",
      "[102]\tTest-mae:0.07935\n",
      "[103]\tTest-mae:0.07925\n",
      "[104]\tTest-mae:0.07914\n",
      "[105]\tTest-mae:0.07903\n",
      "[106]\tTest-mae:0.07894\n",
      "[107]\tTest-mae:0.07878\n",
      "[108]\tTest-mae:0.07863\n",
      "[109]\tTest-mae:0.07856\n",
      "[110]\tTest-mae:0.07848\n",
      "[111]\tTest-mae:0.07840\n",
      "[112]\tTest-mae:0.07826\n",
      "[113]\tTest-mae:0.07812\n",
      "[114]\tTest-mae:0.07804\n",
      "[115]\tTest-mae:0.07794\n",
      "[116]\tTest-mae:0.07784\n",
      "[117]\tTest-mae:0.07779\n",
      "[118]\tTest-mae:0.07776\n",
      "[119]\tTest-mae:0.07773\n",
      "[120]\tTest-mae:0.07770\n",
      "[121]\tTest-mae:0.07763\n",
      "[122]\tTest-mae:0.07758\n",
      "[123]\tTest-mae:0.07754\n",
      "[124]\tTest-mae:0.07745\n",
      "[125]\tTest-mae:0.07737\n",
      "[126]\tTest-mae:0.07727\n",
      "[127]\tTest-mae:0.07723\n",
      "[128]\tTest-mae:0.07716\n",
      "[129]\tTest-mae:0.07709\n",
      "[130]\tTest-mae:0.07702\n",
      "[131]\tTest-mae:0.07699\n",
      "[132]\tTest-mae:0.07689\n",
      "[133]\tTest-mae:0.07682\n",
      "[134]\tTest-mae:0.07674\n",
      "[135]\tTest-mae:0.07672\n",
      "[136]\tTest-mae:0.07663\n",
      "[137]\tTest-mae:0.07658\n",
      "[138]\tTest-mae:0.07656\n",
      "[139]\tTest-mae:0.07647\n",
      "[140]\tTest-mae:0.07641\n",
      "[141]\tTest-mae:0.07636\n",
      "[142]\tTest-mae:0.07632\n",
      "[143]\tTest-mae:0.07629\n",
      "[144]\tTest-mae:0.07624\n",
      "[145]\tTest-mae:0.07613\n",
      "[146]\tTest-mae:0.07605\n",
      "[147]\tTest-mae:0.07599\n",
      "[148]\tTest-mae:0.07596\n",
      "[149]\tTest-mae:0.07588\n",
      "[150]\tTest-mae:0.07584\n",
      "[151]\tTest-mae:0.07578\n",
      "[152]\tTest-mae:0.07576\n",
      "[153]\tTest-mae:0.07572\n",
      "[154]\tTest-mae:0.07571\n",
      "[155]\tTest-mae:0.07562\n",
      "[156]\tTest-mae:0.07555\n",
      "[157]\tTest-mae:0.07550\n",
      "[158]\tTest-mae:0.07546\n",
      "[159]\tTest-mae:0.07543\n",
      "[160]\tTest-mae:0.07535\n",
      "[161]\tTest-mae:0.07534\n",
      "[162]\tTest-mae:0.07524\n",
      "[163]\tTest-mae:0.07519\n",
      "[164]\tTest-mae:0.07513\n",
      "[165]\tTest-mae:0.07508\n",
      "[166]\tTest-mae:0.07505\n",
      "[167]\tTest-mae:0.07502\n",
      "[168]\tTest-mae:0.07502\n",
      "[169]\tTest-mae:0.07499\n",
      "[170]\tTest-mae:0.07494\n",
      "[171]\tTest-mae:0.07493\n",
      "[172]\tTest-mae:0.07493\n",
      "[173]\tTest-mae:0.07490\n",
      "[174]\tTest-mae:0.07484\n",
      "[175]\tTest-mae:0.07482\n",
      "[176]\tTest-mae:0.07478\n",
      "[177]\tTest-mae:0.07476\n",
      "[178]\tTest-mae:0.07470\n",
      "[179]\tTest-mae:0.07467\n",
      "[180]\tTest-mae:0.07466\n",
      "[181]\tTest-mae:0.07462\n",
      "[182]\tTest-mae:0.07460\n",
      "[183]\tTest-mae:0.07459\n",
      "[184]\tTest-mae:0.07454\n",
      "[185]\tTest-mae:0.07451\n",
      "[186]\tTest-mae:0.07450\n",
      "[187]\tTest-mae:0.07446\n",
      "[188]\tTest-mae:0.07440\n",
      "[189]\tTest-mae:0.07436\n",
      "[190]\tTest-mae:0.07434\n",
      "[191]\tTest-mae:0.07429\n",
      "[192]\tTest-mae:0.07428\n",
      "[193]\tTest-mae:0.07424\n",
      "[194]\tTest-mae:0.07420\n",
      "[195]\tTest-mae:0.07416\n",
      "[196]\tTest-mae:0.07412\n",
      "[197]\tTest-mae:0.07411\n",
      "[198]\tTest-mae:0.07406\n",
      "[199]\tTest-mae:0.07403\n",
      "[200]\tTest-mae:0.07401\n",
      "[201]\tTest-mae:0.07396\n",
      "[202]\tTest-mae:0.07394\n",
      "[203]\tTest-mae:0.07393\n",
      "[204]\tTest-mae:0.07388\n",
      "[205]\tTest-mae:0.07384\n",
      "[206]\tTest-mae:0.07379\n",
      "[207]\tTest-mae:0.07377\n",
      "[208]\tTest-mae:0.07372\n",
      "[209]\tTest-mae:0.07369\n",
      "[210]\tTest-mae:0.07369\n",
      "[211]\tTest-mae:0.07368\n",
      "[212]\tTest-mae:0.07365\n",
      "[213]\tTest-mae:0.07362\n",
      "[214]\tTest-mae:0.07360\n",
      "[215]\tTest-mae:0.07359\n",
      "[216]\tTest-mae:0.07357\n",
      "[217]\tTest-mae:0.07354\n",
      "[218]\tTest-mae:0.07351\n",
      "[219]\tTest-mae:0.07350\n",
      "[220]\tTest-mae:0.07350\n",
      "[221]\tTest-mae:0.07349\n",
      "[222]\tTest-mae:0.07347\n",
      "[223]\tTest-mae:0.07344\n",
      "[224]\tTest-mae:0.07343\n",
      "[225]\tTest-mae:0.07342\n",
      "[226]\tTest-mae:0.07340\n",
      "[227]\tTest-mae:0.07339\n",
      "[228]\tTest-mae:0.07338\n",
      "[229]\tTest-mae:0.07334\n",
      "[230]\tTest-mae:0.07333\n",
      "[231]\tTest-mae:0.07330\n",
      "[232]\tTest-mae:0.07326\n",
      "[233]\tTest-mae:0.07325\n",
      "[234]\tTest-mae:0.07320\n",
      "[235]\tTest-mae:0.07316\n",
      "[236]\tTest-mae:0.07314\n",
      "[237]\tTest-mae:0.07309\n",
      "[238]\tTest-mae:0.07308\n",
      "[239]\tTest-mae:0.07306\n",
      "[240]\tTest-mae:0.07304\n",
      "[241]\tTest-mae:0.07303\n",
      "[242]\tTest-mae:0.07302\n",
      "[243]\tTest-mae:0.07297\n",
      "[244]\tTest-mae:0.07296\n",
      "[245]\tTest-mae:0.07295\n",
      "[246]\tTest-mae:0.07293\n",
      "[247]\tTest-mae:0.07293\n",
      "[248]\tTest-mae:0.07290\n",
      "[249]\tTest-mae:0.07289\n",
      "[250]\tTest-mae:0.07287\n",
      "[251]\tTest-mae:0.07286\n",
      "[252]\tTest-mae:0.07283\n",
      "[253]\tTest-mae:0.07281\n",
      "[254]\tTest-mae:0.07277\n",
      "[255]\tTest-mae:0.07271\n",
      "[256]\tTest-mae:0.07271\n",
      "[257]\tTest-mae:0.07267\n",
      "[258]\tTest-mae:0.07264\n",
      "[259]\tTest-mae:0.07262\n",
      "[260]\tTest-mae:0.07258\n",
      "[261]\tTest-mae:0.07255\n",
      "[262]\tTest-mae:0.07252\n",
      "[263]\tTest-mae:0.07252\n",
      "[264]\tTest-mae:0.07250\n",
      "[265]\tTest-mae:0.07249\n",
      "[266]\tTest-mae:0.07248\n",
      "[267]\tTest-mae:0.07246\n",
      "[268]\tTest-mae:0.07243\n",
      "[269]\tTest-mae:0.07243\n",
      "[270]\tTest-mae:0.07243\n",
      "[271]\tTest-mae:0.07242\n",
      "[272]\tTest-mae:0.07241\n",
      "[273]\tTest-mae:0.07240\n",
      "[274]\tTest-mae:0.07239\n",
      "[275]\tTest-mae:0.07237\n",
      "[276]\tTest-mae:0.07236\n",
      "[277]\tTest-mae:0.07235\n",
      "[278]\tTest-mae:0.07235\n",
      "[279]\tTest-mae:0.07229\n",
      "[280]\tTest-mae:0.07228\n",
      "[281]\tTest-mae:0.07225\n",
      "[282]\tTest-mae:0.07222\n",
      "[283]\tTest-mae:0.07219\n",
      "[284]\tTest-mae:0.07214\n",
      "[285]\tTest-mae:0.07211\n",
      "[286]\tTest-mae:0.07209\n",
      "[287]\tTest-mae:0.07208\n",
      "[288]\tTest-mae:0.07204\n",
      "[289]\tTest-mae:0.07201\n",
      "[290]\tTest-mae:0.07199\n",
      "[291]\tTest-mae:0.07198\n",
      "[292]\tTest-mae:0.07197\n",
      "[293]\tTest-mae:0.07195\n",
      "[294]\tTest-mae:0.07195\n",
      "[295]\tTest-mae:0.07195\n",
      "[296]\tTest-mae:0.07193\n",
      "[297]\tTest-mae:0.07192\n",
      "[298]\tTest-mae:0.07191\n",
      "[299]\tTest-mae:0.07188\n",
      "[300]\tTest-mae:0.07185\n",
      "[301]\tTest-mae:0.07182\n",
      "[302]\tTest-mae:0.07181\n",
      "[303]\tTest-mae:0.07178\n",
      "[304]\tTest-mae:0.07175\n",
      "[305]\tTest-mae:0.07174\n",
      "[306]\tTest-mae:0.07172\n",
      "[307]\tTest-mae:0.07171\n",
      "[308]\tTest-mae:0.07171\n",
      "[309]\tTest-mae:0.07170\n",
      "[310]\tTest-mae:0.07168\n",
      "[311]\tTest-mae:0.07166\n",
      "[312]\tTest-mae:0.07164\n",
      "[313]\tTest-mae:0.07162\n",
      "[314]\tTest-mae:0.07160\n",
      "[315]\tTest-mae:0.07157\n",
      "[316]\tTest-mae:0.07156\n",
      "[317]\tTest-mae:0.07155\n",
      "[318]\tTest-mae:0.07152\n",
      "[319]\tTest-mae:0.07150\n",
      "[320]\tTest-mae:0.07149\n",
      "[321]\tTest-mae:0.07148\n",
      "[322]\tTest-mae:0.07147\n",
      "[323]\tTest-mae:0.07145\n",
      "[324]\tTest-mae:0.07143\n",
      "[325]\tTest-mae:0.07142\n",
      "[326]\tTest-mae:0.07141\n",
      "[327]\tTest-mae:0.07140\n",
      "[328]\tTest-mae:0.07139\n",
      "[329]\tTest-mae:0.07139\n",
      "[330]\tTest-mae:0.07134\n",
      "[331]\tTest-mae:0.07134\n",
      "[332]\tTest-mae:0.07134\n",
      "[333]\tTest-mae:0.07133\n",
      "[334]\tTest-mae:0.07132\n",
      "[335]\tTest-mae:0.07129\n",
      "[336]\tTest-mae:0.07125\n",
      "[337]\tTest-mae:0.07124\n",
      "[338]\tTest-mae:0.07124\n",
      "[339]\tTest-mae:0.07123\n",
      "[340]\tTest-mae:0.07122\n",
      "[341]\tTest-mae:0.07121\n",
      "[342]\tTest-mae:0.07120\n",
      "[343]\tTest-mae:0.07119\n",
      "[344]\tTest-mae:0.07116\n",
      "[345]\tTest-mae:0.07113\n",
      "[346]\tTest-mae:0.07111\n",
      "[347]\tTest-mae:0.07108\n",
      "[348]\tTest-mae:0.07107\n",
      "[349]\tTest-mae:0.07107\n",
      "[350]\tTest-mae:0.07105\n",
      "[351]\tTest-mae:0.07104\n",
      "[352]\tTest-mae:0.07101\n",
      "[353]\tTest-mae:0.07099\n",
      "[354]\tTest-mae:0.07098\n",
      "[355]\tTest-mae:0.07097\n",
      "[356]\tTest-mae:0.07096\n",
      "[357]\tTest-mae:0.07095\n",
      "[358]\tTest-mae:0.07094\n",
      "[359]\tTest-mae:0.07093\n",
      "[360]\tTest-mae:0.07093\n",
      "[361]\tTest-mae:0.07093\n",
      "[362]\tTest-mae:0.07093\n",
      "[363]\tTest-mae:0.07092\n",
      "[364]\tTest-mae:0.07091\n",
      "[365]\tTest-mae:0.07089\n",
      "[366]\tTest-mae:0.07088\n",
      "[367]\tTest-mae:0.07086\n",
      "[368]\tTest-mae:0.07085\n",
      "[369]\tTest-mae:0.07083\n",
      "[370]\tTest-mae:0.07082\n",
      "[371]\tTest-mae:0.07081\n",
      "[372]\tTest-mae:0.07081\n",
      "[373]\tTest-mae:0.07078\n",
      "[374]\tTest-mae:0.07078\n",
      "[375]\tTest-mae:0.07077\n",
      "[376]\tTest-mae:0.07076\n",
      "[377]\tTest-mae:0.07075\n",
      "[378]\tTest-mae:0.07073\n",
      "[379]\tTest-mae:0.07070\n",
      "[380]\tTest-mae:0.07070\n",
      "[381]\tTest-mae:0.07069\n",
      "[382]\tTest-mae:0.07067\n",
      "[383]\tTest-mae:0.07064\n",
      "[384]\tTest-mae:0.07062\n",
      "[385]\tTest-mae:0.07060\n",
      "[386]\tTest-mae:0.07059\n",
      "[387]\tTest-mae:0.07057\n",
      "[388]\tTest-mae:0.07054\n",
      "[389]\tTest-mae:0.07054\n",
      "[390]\tTest-mae:0.07052\n",
      "[391]\tTest-mae:0.07052\n",
      "[392]\tTest-mae:0.07051\n",
      "[393]\tTest-mae:0.07051\n",
      "[394]\tTest-mae:0.07051\n",
      "[395]\tTest-mae:0.07048\n",
      "[396]\tTest-mae:0.07047\n",
      "[397]\tTest-mae:0.07048\n",
      "[398]\tTest-mae:0.07047\n",
      "[399]\tTest-mae:0.07047\n",
      "[400]\tTest-mae:0.07046\n",
      "[401]\tTest-mae:0.07046\n",
      "[402]\tTest-mae:0.07045\n",
      "[403]\tTest-mae:0.07045\n",
      "[404]\tTest-mae:0.07045\n",
      "[405]\tTest-mae:0.07044\n",
      "[406]\tTest-mae:0.07040\n",
      "[407]\tTest-mae:0.07039\n",
      "[408]\tTest-mae:0.07037\n",
      "[409]\tTest-mae:0.07037\n",
      "[410]\tTest-mae:0.07036\n",
      "[411]\tTest-mae:0.07035\n",
      "[412]\tTest-mae:0.07034\n",
      "[413]\tTest-mae:0.07034\n",
      "[414]\tTest-mae:0.07033\n",
      "[415]\tTest-mae:0.07032\n",
      "[416]\tTest-mae:0.07032\n",
      "[417]\tTest-mae:0.07031\n",
      "[418]\tTest-mae:0.07030\n",
      "[419]\tTest-mae:0.07027\n",
      "[420]\tTest-mae:0.07024\n",
      "[421]\tTest-mae:0.07022\n",
      "[422]\tTest-mae:0.07020\n",
      "[423]\tTest-mae:0.07020\n",
      "[424]\tTest-mae:0.07017\n",
      "[425]\tTest-mae:0.07016\n",
      "[426]\tTest-mae:0.07015\n",
      "[427]\tTest-mae:0.07013\n",
      "[428]\tTest-mae:0.07011\n",
      "[429]\tTest-mae:0.07010\n",
      "[430]\tTest-mae:0.07008\n",
      "[431]\tTest-mae:0.07006\n",
      "[432]\tTest-mae:0.07005\n",
      "[433]\tTest-mae:0.07004\n",
      "[434]\tTest-mae:0.07002\n",
      "[435]\tTest-mae:0.07000\n",
      "[436]\tTest-mae:0.07000\n",
      "[437]\tTest-mae:0.06999\n",
      "[438]\tTest-mae:0.06999\n",
      "[439]\tTest-mae:0.06998\n",
      "[440]\tTest-mae:0.06998\n",
      "[441]\tTest-mae:0.06996\n",
      "[442]\tTest-mae:0.06995\n",
      "[443]\tTest-mae:0.06993\n",
      "[444]\tTest-mae:0.06991\n",
      "[445]\tTest-mae:0.06990\n",
      "[446]\tTest-mae:0.06988\n",
      "[447]\tTest-mae:0.06988\n",
      "[448]\tTest-mae:0.06986\n",
      "[449]\tTest-mae:0.06986\n",
      "[450]\tTest-mae:0.06986\n",
      "[451]\tTest-mae:0.06985\n",
      "[452]\tTest-mae:0.06983\n",
      "[453]\tTest-mae:0.06983\n",
      "[454]\tTest-mae:0.06982\n",
      "[455]\tTest-mae:0.06981\n",
      "[456]\tTest-mae:0.06978\n",
      "[457]\tTest-mae:0.06977\n",
      "[458]\tTest-mae:0.06977\n",
      "[459]\tTest-mae:0.06975\n",
      "[460]\tTest-mae:0.06975\n",
      "[461]\tTest-mae:0.06975\n",
      "[462]\tTest-mae:0.06973\n",
      "[463]\tTest-mae:0.06970\n",
      "[464]\tTest-mae:0.06970\n",
      "[465]\tTest-mae:0.06968\n",
      "[466]\tTest-mae:0.06967\n",
      "[467]\tTest-mae:0.06966\n",
      "[468]\tTest-mae:0.06964\n",
      "[469]\tTest-mae:0.06964\n",
      "[470]\tTest-mae:0.06962\n",
      "[471]\tTest-mae:0.06962\n",
      "[472]\tTest-mae:0.06961\n",
      "[473]\tTest-mae:0.06959\n",
      "[474]\tTest-mae:0.06959\n",
      "[475]\tTest-mae:0.06958\n",
      "[476]\tTest-mae:0.06957\n",
      "[477]\tTest-mae:0.06956\n",
      "[478]\tTest-mae:0.06956\n",
      "[479]\tTest-mae:0.06955\n",
      "[480]\tTest-mae:0.06953\n",
      "[481]\tTest-mae:0.06952\n",
      "[482]\tTest-mae:0.06950\n",
      "[483]\tTest-mae:0.06949\n",
      "[484]\tTest-mae:0.06946\n",
      "[485]\tTest-mae:0.06945\n",
      "[486]\tTest-mae:0.06944\n",
      "[487]\tTest-mae:0.06943\n",
      "[488]\tTest-mae:0.06941\n",
      "[489]\tTest-mae:0.06942\n",
      "[490]\tTest-mae:0.06940\n",
      "[491]\tTest-mae:0.06940\n",
      "[492]\tTest-mae:0.06938\n",
      "[493]\tTest-mae:0.06938\n",
      "[494]\tTest-mae:0.06937\n",
      "[495]\tTest-mae:0.06936\n",
      "[496]\tTest-mae:0.06936\n",
      "[497]\tTest-mae:0.06936\n",
      "[498]\tTest-mae:0.06935\n",
      "[499]\tTest-mae:0.06934\n",
      "[500]\tTest-mae:0.06932\n",
      "[501]\tTest-mae:0.06931\n",
      "[502]\tTest-mae:0.06929\n",
      "[503]\tTest-mae:0.06929\n",
      "[504]\tTest-mae:0.06929\n",
      "[505]\tTest-mae:0.06928\n",
      "[506]\tTest-mae:0.06927\n",
      "[507]\tTest-mae:0.06926\n",
      "[508]\tTest-mae:0.06926\n",
      "[509]\tTest-mae:0.06925\n",
      "[510]\tTest-mae:0.06924\n",
      "[511]\tTest-mae:0.06924\n",
      "[512]\tTest-mae:0.06923\n",
      "[513]\tTest-mae:0.06921\n",
      "[514]\tTest-mae:0.06920\n",
      "[515]\tTest-mae:0.06920\n",
      "[516]\tTest-mae:0.06920\n",
      "[517]\tTest-mae:0.06920\n",
      "[518]\tTest-mae:0.06920\n",
      "[519]\tTest-mae:0.06920\n",
      "[520]\tTest-mae:0.06919\n",
      "[521]\tTest-mae:0.06918\n",
      "[522]\tTest-mae:0.06917\n",
      "[523]\tTest-mae:0.06917\n",
      "[524]\tTest-mae:0.06916\n",
      "[525]\tTest-mae:0.06916\n",
      "[526]\tTest-mae:0.06916\n",
      "[527]\tTest-mae:0.06916\n",
      "[528]\tTest-mae:0.06915\n",
      "[529]\tTest-mae:0.06914\n",
      "[530]\tTest-mae:0.06914\n",
      "[531]\tTest-mae:0.06914\n",
      "[532]\tTest-mae:0.06914\n",
      "[533]\tTest-mae:0.06913\n",
      "[534]\tTest-mae:0.06912\n",
      "[535]\tTest-mae:0.06912\n",
      "[536]\tTest-mae:0.06912\n",
      "[537]\tTest-mae:0.06912\n",
      "[538]\tTest-mae:0.06911\n",
      "[539]\tTest-mae:0.06911\n",
      "[540]\tTest-mae:0.06910\n",
      "[541]\tTest-mae:0.06909\n",
      "[542]\tTest-mae:0.06909\n",
      "[543]\tTest-mae:0.06907\n",
      "[544]\tTest-mae:0.06907\n",
      "[545]\tTest-mae:0.06906\n",
      "[546]\tTest-mae:0.06906\n",
      "[547]\tTest-mae:0.06906\n",
      "[548]\tTest-mae:0.06905\n",
      "[549]\tTest-mae:0.06904\n",
      "[550]\tTest-mae:0.06904\n",
      "[551]\tTest-mae:0.06904\n",
      "[552]\tTest-mae:0.06904\n",
      "[553]\tTest-mae:0.06903\n",
      "[554]\tTest-mae:0.06901\n",
      "[555]\tTest-mae:0.06900\n",
      "[556]\tTest-mae:0.06899\n",
      "[557]\tTest-mae:0.06899\n",
      "[558]\tTest-mae:0.06897\n",
      "[559]\tTest-mae:0.06896\n",
      "[560]\tTest-mae:0.06895\n",
      "[561]\tTest-mae:0.06895\n",
      "[562]\tTest-mae:0.06894\n",
      "[563]\tTest-mae:0.06893\n",
      "[564]\tTest-mae:0.06892\n",
      "[565]\tTest-mae:0.06892\n",
      "[566]\tTest-mae:0.06891\n",
      "[567]\tTest-mae:0.06890\n",
      "[568]\tTest-mae:0.06890\n",
      "[569]\tTest-mae:0.06889\n",
      "[570]\tTest-mae:0.06889\n",
      "[571]\tTest-mae:0.06887\n",
      "[572]\tTest-mae:0.06887\n",
      "[573]\tTest-mae:0.06886\n",
      "[574]\tTest-mae:0.06886\n",
      "[575]\tTest-mae:0.06886\n",
      "[576]\tTest-mae:0.06886\n",
      "[577]\tTest-mae:0.06885\n",
      "[578]\tTest-mae:0.06885\n",
      "[579]\tTest-mae:0.06885\n",
      "[580]\tTest-mae:0.06885\n",
      "[581]\tTest-mae:0.06885\n",
      "[582]\tTest-mae:0.06885\n",
      "[583]\tTest-mae:0.06884\n",
      "[584]\tTest-mae:0.06883\n",
      "[585]\tTest-mae:0.06882\n",
      "[586]\tTest-mae:0.06881\n",
      "[587]\tTest-mae:0.06879\n",
      "[588]\tTest-mae:0.06879\n",
      "[589]\tTest-mae:0.06878\n",
      "[590]\tTest-mae:0.06877\n",
      "[591]\tTest-mae:0.06875\n",
      "[592]\tTest-mae:0.06875\n",
      "[593]\tTest-mae:0.06874\n",
      "[594]\tTest-mae:0.06873\n",
      "[595]\tTest-mae:0.06873\n",
      "[596]\tTest-mae:0.06872\n",
      "[597]\tTest-mae:0.06872\n",
      "[598]\tTest-mae:0.06872\n",
      "[599]\tTest-mae:0.06871\n",
      "[600]\tTest-mae:0.06870\n",
      "[601]\tTest-mae:0.06870\n",
      "[602]\tTest-mae:0.06867\n",
      "[603]\tTest-mae:0.06867\n",
      "[604]\tTest-mae:0.06866\n",
      "[605]\tTest-mae:0.06865\n",
      "[606]\tTest-mae:0.06865\n",
      "[607]\tTest-mae:0.06864\n",
      "[608]\tTest-mae:0.06863\n",
      "[609]\tTest-mae:0.06863\n",
      "[610]\tTest-mae:0.06862\n",
      "[611]\tTest-mae:0.06861\n",
      "[612]\tTest-mae:0.06861\n",
      "[613]\tTest-mae:0.06860\n",
      "[614]\tTest-mae:0.06859\n",
      "[615]\tTest-mae:0.06859\n",
      "[616]\tTest-mae:0.06859\n",
      "[617]\tTest-mae:0.06858\n",
      "[618]\tTest-mae:0.06857\n",
      "[619]\tTest-mae:0.06857\n",
      "[620]\tTest-mae:0.06856\n",
      "[621]\tTest-mae:0.06856\n",
      "[622]\tTest-mae:0.06856\n",
      "[623]\tTest-mae:0.06855\n",
      "[624]\tTest-mae:0.06855\n",
      "[625]\tTest-mae:0.06854\n",
      "[626]\tTest-mae:0.06854\n",
      "[627]\tTest-mae:0.06854\n",
      "[628]\tTest-mae:0.06853\n",
      "[629]\tTest-mae:0.06853\n",
      "[630]\tTest-mae:0.06852\n",
      "[631]\tTest-mae:0.06851\n",
      "[632]\tTest-mae:0.06849\n",
      "[633]\tTest-mae:0.06849\n",
      "[634]\tTest-mae:0.06849\n",
      "[635]\tTest-mae:0.06848\n",
      "[636]\tTest-mae:0.06847\n",
      "[637]\tTest-mae:0.06846\n",
      "[638]\tTest-mae:0.06845\n",
      "[639]\tTest-mae:0.06844\n",
      "[640]\tTest-mae:0.06843\n",
      "[641]\tTest-mae:0.06842\n",
      "[642]\tTest-mae:0.06841\n",
      "[643]\tTest-mae:0.06841\n",
      "[644]\tTest-mae:0.06841\n",
      "[645]\tTest-mae:0.06840\n",
      "[646]\tTest-mae:0.06839\n",
      "[647]\tTest-mae:0.06839\n",
      "[648]\tTest-mae:0.06838\n",
      "[649]\tTest-mae:0.06837\n",
      "[650]\tTest-mae:0.06837\n",
      "[651]\tTest-mae:0.06836\n",
      "[652]\tTest-mae:0.06836\n",
      "[653]\tTest-mae:0.06836\n",
      "[654]\tTest-mae:0.06836\n",
      "[655]\tTest-mae:0.06836\n",
      "[656]\tTest-mae:0.06835\n",
      "[657]\tTest-mae:0.06835\n",
      "[658]\tTest-mae:0.06835\n",
      "[659]\tTest-mae:0.06835\n",
      "[660]\tTest-mae:0.06834\n",
      "[661]\tTest-mae:0.06834\n",
      "[662]\tTest-mae:0.06834\n",
      "[663]\tTest-mae:0.06833\n",
      "[664]\tTest-mae:0.06833\n",
      "[665]\tTest-mae:0.06833\n",
      "[666]\tTest-mae:0.06831\n",
      "[667]\tTest-mae:0.06829\n",
      "[668]\tTest-mae:0.06828\n",
      "[669]\tTest-mae:0.06828\n",
      "[670]\tTest-mae:0.06827\n",
      "[671]\tTest-mae:0.06827\n",
      "[672]\tTest-mae:0.06826\n",
      "[673]\tTest-mae:0.06826\n",
      "[674]\tTest-mae:0.06826\n",
      "[675]\tTest-mae:0.06826\n",
      "[676]\tTest-mae:0.06825\n",
      "[677]\tTest-mae:0.06825\n",
      "[678]\tTest-mae:0.06824\n",
      "[679]\tTest-mae:0.06824\n",
      "[680]\tTest-mae:0.06824\n",
      "[681]\tTest-mae:0.06824\n",
      "[682]\tTest-mae:0.06822\n",
      "[683]\tTest-mae:0.06822\n",
      "[684]\tTest-mae:0.06821\n",
      "[685]\tTest-mae:0.06821\n",
      "[686]\tTest-mae:0.06820\n",
      "[687]\tTest-mae:0.06820\n",
      "[688]\tTest-mae:0.06819\n",
      "[689]\tTest-mae:0.06818\n",
      "[690]\tTest-mae:0.06818\n",
      "[691]\tTest-mae:0.06816\n",
      "[692]\tTest-mae:0.06815\n",
      "[693]\tTest-mae:0.06815\n",
      "[694]\tTest-mae:0.06815\n",
      "[695]\tTest-mae:0.06815\n",
      "[696]\tTest-mae:0.06815\n",
      "[697]\tTest-mae:0.06814\n",
      "[698]\tTest-mae:0.06813\n",
      "[699]\tTest-mae:0.06813\n",
      "[700]\tTest-mae:0.06813\n",
      "[701]\tTest-mae:0.06813\n",
      "[702]\tTest-mae:0.06813\n",
      "[703]\tTest-mae:0.06813\n",
      "[704]\tTest-mae:0.06813\n",
      "[705]\tTest-mae:0.06812\n",
      "[706]\tTest-mae:0.06811\n",
      "[707]\tTest-mae:0.06811\n",
      "[708]\tTest-mae:0.06811\n",
      "[709]\tTest-mae:0.06811\n",
      "[710]\tTest-mae:0.06810\n",
      "[711]\tTest-mae:0.06810\n",
      "[712]\tTest-mae:0.06810\n",
      "[713]\tTest-mae:0.06809\n",
      "[714]\tTest-mae:0.06809\n",
      "[715]\tTest-mae:0.06809\n",
      "[716]\tTest-mae:0.06808\n",
      "[717]\tTest-mae:0.06808\n",
      "[718]\tTest-mae:0.06807\n",
      "[719]\tTest-mae:0.06807\n",
      "[720]\tTest-mae:0.06806\n",
      "[721]\tTest-mae:0.06806\n",
      "[722]\tTest-mae:0.06805\n",
      "[723]\tTest-mae:0.06805\n",
      "[724]\tTest-mae:0.06805\n",
      "[725]\tTest-mae:0.06805\n",
      "[726]\tTest-mae:0.06804\n",
      "[727]\tTest-mae:0.06804\n",
      "[728]\tTest-mae:0.06803\n",
      "[729]\tTest-mae:0.06804\n",
      "[730]\tTest-mae:0.06803\n",
      "[731]\tTest-mae:0.06802\n",
      "[732]\tTest-mae:0.06802\n",
      "[733]\tTest-mae:0.06801\n",
      "[734]\tTest-mae:0.06802\n",
      "[735]\tTest-mae:0.06800\n",
      "[736]\tTest-mae:0.06800\n",
      "[737]\tTest-mae:0.06799\n",
      "[738]\tTest-mae:0.06799\n",
      "[739]\tTest-mae:0.06799\n",
      "[740]\tTest-mae:0.06798\n",
      "[741]\tTest-mae:0.06797\n",
      "[742]\tTest-mae:0.06797\n",
      "[743]\tTest-mae:0.06797\n",
      "[744]\tTest-mae:0.06797\n",
      "[745]\tTest-mae:0.06796\n",
      "[746]\tTest-mae:0.06796\n",
      "[747]\tTest-mae:0.06796\n",
      "[748]\tTest-mae:0.06796\n",
      "[749]\tTest-mae:0.06795\n",
      "[750]\tTest-mae:0.06794\n",
      "[751]\tTest-mae:0.06794\n",
      "[752]\tTest-mae:0.06793\n",
      "[753]\tTest-mae:0.06792\n",
      "[754]\tTest-mae:0.06792\n",
      "[755]\tTest-mae:0.06792\n",
      "[756]\tTest-mae:0.06792\n",
      "[757]\tTest-mae:0.06791\n",
      "[758]\tTest-mae:0.06791\n",
      "[759]\tTest-mae:0.06791\n",
      "[760]\tTest-mae:0.06790\n",
      "[761]\tTest-mae:0.06790\n",
      "[762]\tTest-mae:0.06789\n",
      "[763]\tTest-mae:0.06789\n",
      "[764]\tTest-mae:0.06788\n",
      "[765]\tTest-mae:0.06788\n",
      "[766]\tTest-mae:0.06789\n",
      "[767]\tTest-mae:0.06789\n",
      "[768]\tTest-mae:0.06788\n",
      "[769]\tTest-mae:0.06788\n",
      "[770]\tTest-mae:0.06787\n",
      "[771]\tTest-mae:0.06787\n",
      "[772]\tTest-mae:0.06786\n",
      "[773]\tTest-mae:0.06785\n",
      "[774]\tTest-mae:0.06784\n",
      "[775]\tTest-mae:0.06782\n",
      "[776]\tTest-mae:0.06782\n",
      "[777]\tTest-mae:0.06782\n",
      "[778]\tTest-mae:0.06782\n",
      "[779]\tTest-mae:0.06782\n",
      "[780]\tTest-mae:0.06782\n",
      "[781]\tTest-mae:0.06781\n",
      "[782]\tTest-mae:0.06781\n",
      "[783]\tTest-mae:0.06780\n",
      "[784]\tTest-mae:0.06779\n",
      "[785]\tTest-mae:0.06779\n",
      "[786]\tTest-mae:0.06778\n",
      "[787]\tTest-mae:0.06777\n",
      "[788]\tTest-mae:0.06777\n",
      "[789]\tTest-mae:0.06776\n",
      "[790]\tTest-mae:0.06776\n",
      "[791]\tTest-mae:0.06775\n",
      "[792]\tTest-mae:0.06775\n",
      "[793]\tTest-mae:0.06775\n",
      "[794]\tTest-mae:0.06775\n",
      "[795]\tTest-mae:0.06774\n",
      "[796]\tTest-mae:0.06774\n",
      "[797]\tTest-mae:0.06774\n",
      "[798]\tTest-mae:0.06774\n",
      "[799]\tTest-mae:0.06773\n",
      "[800]\tTest-mae:0.06773\n",
      "[801]\tTest-mae:0.06772\n",
      "[802]\tTest-mae:0.06772\n",
      "[803]\tTest-mae:0.06771\n",
      "[804]\tTest-mae:0.06771\n",
      "[805]\tTest-mae:0.06771\n",
      "[806]\tTest-mae:0.06771\n",
      "[807]\tTest-mae:0.06770\n",
      "[808]\tTest-mae:0.06770\n",
      "[809]\tTest-mae:0.06770\n",
      "[810]\tTest-mae:0.06768\n",
      "[811]\tTest-mae:0.06768\n",
      "[812]\tTest-mae:0.06767\n",
      "[813]\tTest-mae:0.06767\n",
      "[814]\tTest-mae:0.06767\n",
      "[815]\tTest-mae:0.06767\n",
      "[816]\tTest-mae:0.06767\n",
      "[817]\tTest-mae:0.06767\n",
      "[818]\tTest-mae:0.06766\n",
      "[819]\tTest-mae:0.06766\n",
      "[820]\tTest-mae:0.06765\n",
      "[821]\tTest-mae:0.06765\n",
      "[822]\tTest-mae:0.06764\n",
      "[823]\tTest-mae:0.06764\n",
      "[824]\tTest-mae:0.06764\n",
      "[825]\tTest-mae:0.06763\n",
      "[826]\tTest-mae:0.06762\n",
      "[827]\tTest-mae:0.06762\n",
      "[828]\tTest-mae:0.06761\n",
      "[829]\tTest-mae:0.06761\n",
      "[830]\tTest-mae:0.06760\n",
      "[831]\tTest-mae:0.06760\n",
      "[832]\tTest-mae:0.06760\n",
      "[833]\tTest-mae:0.06759\n",
      "[834]\tTest-mae:0.06759\n",
      "[835]\tTest-mae:0.06759\n",
      "[836]\tTest-mae:0.06758\n",
      "[837]\tTest-mae:0.06758\n",
      "[838]\tTest-mae:0.06757\n",
      "[839]\tTest-mae:0.06757\n",
      "[840]\tTest-mae:0.06757\n",
      "[841]\tTest-mae:0.06757\n",
      "[842]\tTest-mae:0.06756\n",
      "[843]\tTest-mae:0.06756\n",
      "[844]\tTest-mae:0.06756\n",
      "[845]\tTest-mae:0.06755\n",
      "[846]\tTest-mae:0.06754\n",
      "[847]\tTest-mae:0.06754\n",
      "[848]\tTest-mae:0.06754\n",
      "[849]\tTest-mae:0.06753\n",
      "[850]\tTest-mae:0.06753\n",
      "[851]\tTest-mae:0.06752\n",
      "[852]\tTest-mae:0.06752\n",
      "[853]\tTest-mae:0.06752\n",
      "[854]\tTest-mae:0.06752\n",
      "[855]\tTest-mae:0.06751\n",
      "[856]\tTest-mae:0.06750\n",
      "[857]\tTest-mae:0.06750\n",
      "[858]\tTest-mae:0.06750\n",
      "[859]\tTest-mae:0.06750\n",
      "[860]\tTest-mae:0.06750\n",
      "[861]\tTest-mae:0.06750\n",
      "[862]\tTest-mae:0.06750\n",
      "[863]\tTest-mae:0.06749\n",
      "[864]\tTest-mae:0.06749\n",
      "[865]\tTest-mae:0.06749\n",
      "[866]\tTest-mae:0.06748\n",
      "[867]\tTest-mae:0.06748\n",
      "[868]\tTest-mae:0.06748\n",
      "[869]\tTest-mae:0.06748\n",
      "[870]\tTest-mae:0.06748\n",
      "[871]\tTest-mae:0.06747\n",
      "[872]\tTest-mae:0.06747\n",
      "[873]\tTest-mae:0.06746\n",
      "[874]\tTest-mae:0.06746\n",
      "[875]\tTest-mae:0.06746\n",
      "[876]\tTest-mae:0.06745\n",
      "[877]\tTest-mae:0.06745\n",
      "[878]\tTest-mae:0.06745\n",
      "[879]\tTest-mae:0.06744\n",
      "[880]\tTest-mae:0.06743\n",
      "[881]\tTest-mae:0.06743\n",
      "[882]\tTest-mae:0.06743\n",
      "[883]\tTest-mae:0.06742\n",
      "[884]\tTest-mae:0.06741\n",
      "[885]\tTest-mae:0.06741\n",
      "[886]\tTest-mae:0.06741\n",
      "[887]\tTest-mae:0.06740\n",
      "[888]\tTest-mae:0.06740\n",
      "[889]\tTest-mae:0.06739\n",
      "[890]\tTest-mae:0.06739\n",
      "[891]\tTest-mae:0.06739\n",
      "[892]\tTest-mae:0.06738\n",
      "[893]\tTest-mae:0.06737\n",
      "[894]\tTest-mae:0.06737\n",
      "[895]\tTest-mae:0.06736\n",
      "[896]\tTest-mae:0.06736\n",
      "[897]\tTest-mae:0.06736\n",
      "[898]\tTest-mae:0.06736\n",
      "[899]\tTest-mae:0.06736\n",
      "[900]\tTest-mae:0.06735\n",
      "[901]\tTest-mae:0.06735\n",
      "[902]\tTest-mae:0.06735\n",
      "[903]\tTest-mae:0.06735\n",
      "[904]\tTest-mae:0.06734\n",
      "[905]\tTest-mae:0.06734\n",
      "[906]\tTest-mae:0.06734\n",
      "[907]\tTest-mae:0.06735\n",
      "[908]\tTest-mae:0.06734\n",
      "[909]\tTest-mae:0.06734\n",
      "[910]\tTest-mae:0.06734\n",
      "[911]\tTest-mae:0.06734\n",
      "[912]\tTest-mae:0.06734\n",
      "[913]\tTest-mae:0.06733\n",
      "[914]\tTest-mae:0.06733\n",
      "[915]\tTest-mae:0.06732\n",
      "[916]\tTest-mae:0.06732\n",
      "[917]\tTest-mae:0.06731\n",
      "[918]\tTest-mae:0.06730\n",
      "[919]\tTest-mae:0.06730\n",
      "[920]\tTest-mae:0.06729\n",
      "[921]\tTest-mae:0.06729\n",
      "[922]\tTest-mae:0.06729\n",
      "[923]\tTest-mae:0.06728\n",
      "[924]\tTest-mae:0.06727\n",
      "[925]\tTest-mae:0.06727\n",
      "[926]\tTest-mae:0.06727\n",
      "[927]\tTest-mae:0.06727\n",
      "[928]\tTest-mae:0.06726\n",
      "[929]\tTest-mae:0.06726\n",
      "[930]\tTest-mae:0.06726\n",
      "[931]\tTest-mae:0.06726\n",
      "[932]\tTest-mae:0.06725\n",
      "[933]\tTest-mae:0.06724\n",
      "[934]\tTest-mae:0.06724\n",
      "[935]\tTest-mae:0.06724\n",
      "[936]\tTest-mae:0.06723\n",
      "[937]\tTest-mae:0.06723\n",
      "[938]\tTest-mae:0.06723\n",
      "[939]\tTest-mae:0.06722\n",
      "[940]\tTest-mae:0.06722\n",
      "[941]\tTest-mae:0.06722\n",
      "[942]\tTest-mae:0.06722\n",
      "[943]\tTest-mae:0.06721\n",
      "[944]\tTest-mae:0.06721\n",
      "[945]\tTest-mae:0.06720\n",
      "[946]\tTest-mae:0.06719\n",
      "[947]\tTest-mae:0.06719\n",
      "[948]\tTest-mae:0.06719\n",
      "[949]\tTest-mae:0.06719\n",
      "[950]\tTest-mae:0.06719\n",
      "[951]\tTest-mae:0.06719\n",
      "[952]\tTest-mae:0.06719\n",
      "[953]\tTest-mae:0.06718\n",
      "[954]\tTest-mae:0.06718\n",
      "[955]\tTest-mae:0.06718\n",
      "[956]\tTest-mae:0.06718\n",
      "[957]\tTest-mae:0.06718\n",
      "[958]\tTest-mae:0.06718\n",
      "[959]\tTest-mae:0.06717\n",
      "[960]\tTest-mae:0.06717\n",
      "[961]\tTest-mae:0.06716\n",
      "[962]\tTest-mae:0.06716\n",
      "[963]\tTest-mae:0.06715\n",
      "[964]\tTest-mae:0.06715\n",
      "[965]\tTest-mae:0.06715\n",
      "[966]\tTest-mae:0.06714\n",
      "[967]\tTest-mae:0.06714\n",
      "[968]\tTest-mae:0.06713\n",
      "[969]\tTest-mae:0.06713\n",
      "[970]\tTest-mae:0.06713\n",
      "[971]\tTest-mae:0.06713\n",
      "[972]\tTest-mae:0.06712\n",
      "[973]\tTest-mae:0.06712\n",
      "[974]\tTest-mae:0.06712\n",
      "[975]\tTest-mae:0.06711\n",
      "[976]\tTest-mae:0.06711\n",
      "[977]\tTest-mae:0.06711\n",
      "[978]\tTest-mae:0.06711\n",
      "[979]\tTest-mae:0.06710\n",
      "[980]\tTest-mae:0.06710\n",
      "[981]\tTest-mae:0.06710\n",
      "[982]\tTest-mae:0.06710\n",
      "[983]\tTest-mae:0.06710\n",
      "[984]\tTest-mae:0.06710\n",
      "[985]\tTest-mae:0.06710\n",
      "[986]\tTest-mae:0.06709\n",
      "[987]\tTest-mae:0.06709\n",
      "[988]\tTest-mae:0.06709\n",
      "[989]\tTest-mae:0.06709\n",
      "[990]\tTest-mae:0.06709\n",
      "[991]\tTest-mae:0.06709\n",
      "[992]\tTest-mae:0.06708\n",
      "[993]\tTest-mae:0.06708\n",
      "[994]\tTest-mae:0.06707\n",
      "[995]\tTest-mae:0.06707\n",
      "[996]\tTest-mae:0.06706\n",
      "[997]\tTest-mae:0.06706\n",
      "[998]\tTest-mae:0.06706\n",
      "[999]\tTest-mae:0.06706\n",
      "Best MAE: 0.06706 with 999 rounds\n",
      "CV with max_depth=11, min_child_weight=8\n",
      "[03:15:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:15:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:15:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:15:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:15:28] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.069919 for 999 rounds\n",
      "CV with max_depth=11, min_child_weight=9\n",
      "[03:31:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:31:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:31:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:31:17] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:31:17] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.07013180000000001 for 999 rounds\n",
      "CV with max_depth=11, min_child_weight=10\n",
      "[03:46:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:46:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:46:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:46:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:46:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.07012679999999999 for 999 rounds\n",
      "CV with max_depth=12, min_child_weight=8\n",
      "[04:02:26] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:02:26] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:02:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:02:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:02:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.0702124 for 999 rounds\n",
      "CV with max_depth=12, min_child_weight=9\n",
      "[04:20:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:20:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:20:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:20:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:20:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.07011719999999999 for 999 rounds\n",
      "CV with max_depth=12, min_child_weight=10\n",
      "[04:38:39] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:38:40] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:38:40] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:38:40] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:38:41] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.0701062 for 999 rounds\n",
      "CV with max_depth=13, min_child_weight=8\n",
      "[04:55:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:55:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:55:45] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:55:45] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:55:45] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.070689 for 999 rounds\n",
      "CV with max_depth=13, min_child_weight=9\n",
      "[05:14:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:14:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:14:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:14:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:14:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.0706094 for 998 rounds\n",
      "CV with max_depth=13, min_child_weight=10\n",
      "[05:33:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:33:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:33:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:33:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:33:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.0705632 for 999 rounds\n",
      "CV with max_depth=14, min_child_weight=8\n",
      "[05:52:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:52:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:52:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:52:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:52:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.0710986 for 999 rounds\n",
      "CV with max_depth=14, min_child_weight=9\n",
      "[06:13:10] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:13:10] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:13:10] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:13:11] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:13:11] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.0710364 for 999 rounds\n",
      "CV with max_depth=14, min_child_weight=10\n",
      "[06:33:38] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:33:39] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:33:39] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:33:39] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:33:40] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.0708992 for 999 rounds\n",
      "Best params: 11, 8, MAE: 0.069919\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "[06:53:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:53:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:53:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:53:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:54:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\tMAE 0.0700934 for 999 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "[07:11:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[07:11:17] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[07:11:17] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[07:11:17] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[07:11:17] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def read_folder(file_folder):\r\n",
    "    \"\"\"\r\n",
    "        Read all files in the folder\r\n",
    "        \"\"\"\r\n",
    "    files = os.listdir(file_folder)\r\n",
    "    df = []\r\n",
    "    for f in files:\r\n",
    "        print(f)\r\n",
    "        my_file = file_folder + \"/\" + f\r\n",
    "        temp = pd.read_csv(my_file, sep=';')\r\n",
    "        temp['file_name']=f\r\n",
    "        df.append(temp)\r\n",
    "    df_full = pd.concat(df, ignore_index=True)\r\n",
    "    return df_full\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_full = read_folder(\r\n",
    "    \"C:/Users/xi-lucy.chen/Documents/GitLab/data_challenge_alc_total/phase_2_Lucy/result/before_submission/\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "predictions_end_date_201101.csv\n",
      "predictions_end_date_201102.csv\n",
      "predictions_end_date_201103.csv\n",
      "predictions_end_date_201104.csv\n",
      "predictions_end_date_201105.csv\n",
      "predictions_end_date_201106.csv\n",
      "predictions_end_date_201107.csv\n",
      "predictions_end_date_201108.csv\n",
      "predictions_end_date_201109.csv\n",
      "predictions_end_date_201110.csv\n",
      "predictions_end_date_201111.csv\n",
      "predictions_end_date_201112.csv\n",
      "predictions_end_date_201201.csv\n",
      "predictions_end_date_201202.csv\n",
      "predictions_end_date_201203.csv\n",
      "predictions_end_date_201204.csv\n",
      "predictions_end_date_201205.csv\n",
      "predictions_end_date_201206.csv\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_full['file_forecast_month'] = df_full['file_name'].str[21:27]\r\n",
    "df_full['forecast_month'] = df_full['date'].astype(str).str[0:6]\r\n",
    "\r\n",
    "df_full['match'] = np.where(df_full['file_forecast_month']\r\n",
    "                       == df_full['forecast_month'],True,False)\r\n",
    "df_full=df_full[df_full['match']==True]\r\n",
    "prediction = df_full.drop(\r\n",
    "    columns=['file_forecast_month', 'match', 'file_name', 'forecast_month'])\r\n",
    "save_address2 = 'C:/Users/xi-lucy.chen/Documents/GitLab/data_challenge_alc_total/phase_2_Lucy/result/submission/'\r\n",
    "prediction.to_csv(\r\n",
    "    save_address2+'predictions_{}.csv'.format(date.today()), index=False, sep=';')\r\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nimport xgboost as xgb'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Merge predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "read_address = 'C:/Users/xi-lucy.chen/Documents/GitLab/data_challenge_alc_total/phase 2 model/Lucy/result/'\r\n",
    "pred_wp1=pd.read_csv(read_address+\"pred_wp1.csv\")\r\n",
    "pred_wp2=pd.read_csv(read_address+\"pred_wp2.csv\")\r\n",
    "pred_wp3=pd.read_csv(read_address+\"pred_wp3.csv\")\r\n",
    "pred_wp4=pd.read_csv(read_address+\"pred_wp4.csv\")\r\n",
    "pred_wp5=pd.read_csv(read_address+\"pred_wp5.csv\")\r\n",
    "pred_wp6=pd.read_csv(read_address+\"pred_wp6.csv\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# read_address = 'C:/Users/xi-lucy.chen/Documents/GitLab/data_challenge_alc_total/phase 2 model/Lucy/result/'\r\n",
    "# save_address = 'C:/Users/xi-lucy.chen/Documents/GitLab/data_challenge_alc_total/phase 2 model/Lucy/result/submission/'\r\n",
    "# pred1=pd.read_csv(read_address+'pred_wp1.csv')\r\n",
    "# pred2=pd.read_csv(read_address+'pred_wp2.csv')\r\n",
    "# pred3=pd.read_csv(read_address+'pred_wp3.csv')\r\n",
    "# pred4=pd.read_csv(read_address+'pred_wp4.csv')\r\n",
    "# pred5=pd.read_csv(read_address+'pred_wp5.csv')\r\n",
    "# pred6 = pd.read_csv(read_address+'pred_wp6.csv')\r\n",
    "\r\n",
    "# merge_pred=pd.DataFrame()\r\n",
    "# merge_pred=pred1\r\n",
    "# merge_pred = merge_pred.merge(pred2,on='date')\r\n",
    "# merge_pred = merge_pred.merge(pred3,on='date')\r\n",
    "# merge_pred = merge_pred.merge(pred4,on='date')\r\n",
    "# merge_pred = merge_pred.merge(pred5,on='date')\r\n",
    "# merge_pred = merge_pred.merge(pred6,on='date')\r\n",
    "\r\n",
    "\r\n",
    "# merge_pred.to_csv('predictions.csv', index=False, sep=';')\r\n",
    "# df_predictions.head()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import json\r\n",
    "model_address = 'C:/Users/xi-lucy.chen/Documents/GitLab/data_challenge_alc_total/phase_2_Lucy/model/'\r\n",
    "def read_my_json(model_address,my_file):\r\n",
    "    f = open(model_address+my_file)\r\n",
    "    json_file = json.load(f)\r\n",
    "    return json_file\r\n",
    "\r\n",
    "\r\n",
    "param1 = json.loads(read_my_json(model_address,'param_wp1.json'))\r\n",
    "param2 = json.loads(read_my_json(model_address, 'param_wp2.json'))\r\n",
    "param3=json.loads(read_my_json(model_address, 'param_wp3.json'))\r\n",
    "param4=json.loads(read_my_json(model_address, 'param_wp4.json'))\r\n",
    "param5=json.loads(read_my_json(model_address, 'param_wp5.json'))\r\n",
    "param6=json.loads(read_my_json(model_address, 'param_wp6.json'))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.json_normalize(param1)\r\n",
    "df=df.append(pd.json_normalize(param2))\r\n",
    "df=df.append(pd.json_normalize(param3))\r\n",
    "df=df.append(pd.json_normalize(param4))\r\n",
    "df=df.append(pd.json_normalize(param5))\r\n",
    "df = df.append(pd.json_normalize(param6))\r\n",
    "df=df.reset_index(drop=True)\r\n",
    "df.to_csv(model_address + 'my_tuned_params.csv')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f94b3753c628799450866864c7093af0e90533b360fa82307d357e1f74a9ff1"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}